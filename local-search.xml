<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《SSA Book》- 11. 基于SSA的If-conversion</title>
    <link href="/2022/05/07/ssa-book-11/"/>
    <url>/2022/05/07/ssa-book-11/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--11.-基于ssa的if-conversion">《SSA Book》- 11.基于SSA的If-conversion</h1><p>在之前的《编译后端优化：If-Conversion算法与LLVM实现》中已经讨论了If-Conversion算法。在《SSAbook》的第20章同样套路了这个算法，相对可能更深入一些，这里进行一个介绍。</p><h2 id="实现if-conversion的硬件需求">实现If-conversion的硬件需求</h2><p>转换时的操作合并有不同的实现方式，我们区分了以下三种条件执行模型:</p><ol type="1"><li>Fully predicatedexecution：任何指令都可以根据谓词操作数的值有条件地执行；</li><li>Speculative execution：使用cmov或者select等指令实现条件执行；</li><li>Partially predicatedexecution：一部分指令具有predicate，其他操作是正常执行的。</li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-07-22-14-04.png"alt="使用不同模型的条件执行模式" /><figcaption aria-hidden="true">使用不同模型的条件执行模式</figcaption></figure><p>无论用哪种方式，都需要考虑如何避免因为执行了原本不执行的代码带来的副作用，特别是存储操作。在某些硬件中有带条件的内存控制操作，但有些没有，这些都要考虑如何去处理。</p><p>本章首先将CFG区域转换成SSA形式，产生一个if-converted的SSA表示。然后，我们将使用ψ-SSA形式，描述如何将这个框架扩展到使用谓词指令。最后，我们提出了一个全局框架，将这些技术汇集在一起，逐渐扩大if-converted区域的范围。</p><h2 id="基本转换">基本转换</h2><p>最简单的方法是对if-then-else-exit的处理方式，被称为Φ-reduction过程。过程分为几步：</p><ol type="1"><li>将两个分支中语句提升到头部基本块之中；</li><li>把Φ指令替换为select语句；</li><li>将控制流简化为单个基本块。</li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-07-22-11-09.png"alt="Φ-reduction过程" /><figcaption aria-hidden="true">Φ-reduction过程</figcaption></figure><p>在原书的第14章中提到了gated-SSA，即一个Φ函数可以接受多个前驱的变量。对于这种情况，可以先将其分解成多个Φ函数，接着就得到了菱形形式的if-then-else，这样就可以Φ-reduction过程合并了。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-07-22-32-05.png"alt="针对多参数的Φ函数的Φ-reduction" /><figcaptionaria-hidden="true">针对多参数的Φ函数的Φ-reduction</figcaption></figure><p>此外，还有一种方法“路径复制”。考虑两个不同的节点，入口<spanclass="math inline">\(head\)</span>和出口<spanclass="math inline">\(exit\)</span>，从<spanclass="math inline">\(head\)</span>到<spanclass="math inline">\(exit\)</span>有两个不同的控制流路径；假设路径<spanclass="math inline">\(P=head\rightarrow side_0\rightarrow \dots\rightarrow side_p\rightarrow exit\)</span>的路径中<spanclass="math inline">\(side_i\)</span>具有两个前驱。那么，路径复制方法就是把<spanclass="math inline">\(side_i\rightarrow \dots \rightarrowside_p\)</span>部分复制一份，得到路径<spanclass="math inline">\(P&#39;=side_i&#39;\rightarrow \dots \rightarrowside_p&#39;→exit\)</span>。接着路径复制算法将<spanclass="math inline">\(side_{i-1}\)</span>接到路径P'上。这样复制出来的新路径就构成了标准的菱形Φ形式。接着对菱形形式中的代码进行一个变量重命名二和复制传播，即可进行Φ-reduction了。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-07-22-45-46.png"alt="路径复制的例子" /><figcaption aria-hidden="true">路径复制的例子</figcaption></figure><p>最后的一种方法叫做“Conjunctive predicatemerge”，简单来说，就是对原有的predicate进行and和or的分解、合并，使得最终得到菱形Φ形式。下面即为一个典型的例子：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-07-22-49-31.png"alt="Conjunctive predicate merge的例子" /><figcaption aria-hidden="true">Conjunctive predicatemerge的例子</figcaption></figure><p>上面这些方法可以同样在non-SSA形式的程序上起到效果，但是需要花更多步骤：需要进行额外的变量重命名，需要进行全局的数据流分析。而对于SSA形式，则能够不需要进行额外的重命名。此外，在prunedSSA上，还能取得更好的优化效果，因为死代码都提前被删除了。</p><h2 id="对predicated执行模式的处理">对predicated执行模式的处理</h2><p>之前讨论的主要是speculative executionmodel，即为不同的指令提供一个令牌判断是否执行（比如select、cmov），这样子原本不会执行的指令会被执行，只是部分选择结果，使得看上去像没有执行一样。而接下来要介绍的是predicatedexecution model，即使用predicate为指令进行修饰的处理方式。</p><p>在合并基本块的过程中，使用speculative或是predicated方式合并，本身即为一个优化过程。以下面的图为例，该程序使用了Ψ-SSA的结构。相对于传统的SSA，这种结构能够将Φ函数以Ψ函数的形式，保留到合并之后的基本块中，且Ψ函数保留了选择不同的变量的谓词条件。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-08-09-42-40.png"alt="Speculation的使用" /><figcaption aria-hidden="true">Speculation的使用</figcaption></figure><p>上图中的图(a)采用了fullypredicated的方式，为每个语句都添加了谓词，这样的方法要求语句1必须在语句2和3之前执行，限制了并行性。</p><p>图(b)则采用了fullyspeculated的方式，语句1-3均可并行乱序执行，这种方法在析构Ψ函数之后，将会多生成一个select指令，最后构成4条指令。</p><p>图(c)采用了partiallyspeculated的方法，只有x1是speculated的，这样子就可以合并成为图(d)的形式，但是这样又为程序添加了输出依赖，即第2、3条语句之间不能并行执行。</p><p>在实际的φ-reduction过程中，只要有可能，就优先进行speculation（除了有副作用的操作，比如store那种）。这些代码被提取到if语句之前，就可以在判断之前就进行这些操作。当一个指令被决定predicated或是speculative之后，对于一个菱形if结构，它的φ函数可以被ψ函数取代，speculated操作、谓词计算被放在第一位，predicated操作紧随其后，由对应的谓词所修饰。</p><h2 id="全局分析">全局分析</h2><p>之前的转换能把if-then-else-end区域转化为单基本块，但仍然存在很多问题：寄存器的数量将限制了数据依赖的长度；谓词寄存器的数量将决定if转换的深度；处理器的数量将决定可以同时执行的指令的数量。因此，需要全局地分析，本章的inner-outer增量过程可以很好地评价采用if-conversion能带来多大的收益。</p><h3 id="ssa增量if-conversion算法">SSA增量if-conversion算法</h3><p>该算法以SSA形式的CFG作为输入，后序遍历基本块，并利用上一节中的if-converted转换方法进行增量约简。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-08-12-16-37.png"alt="word count程序的增量约简过程" /><figcaption aria-hidden="true">word count程序的增量约简过程</figcaption></figure><p>原文的描述和上图好像有冲突，我试着用我自己的理解分析。在上图中，针对以BB7的分析的由内到外的逆序分析序列应该为：[BB14,BB13,BB11,BB9,BB8,BB7]。</p><ol type="1"><li>第一个考虑的是BB14，因为BB15有别的前驱，我们考虑一个复制，这样子就可以把[BB14,BB15',BB2]合并了，形成新的节点BB14'；</li><li>对于BB13，就可以合并[BB13,BB14',BB15',BB2]了，得到新的节点BB13'；</li><li>对于BB11，合并[BB11,BB12,BB13',BB2]，得到节点BB11'；</li><li>对于BB9，合并[BB9,BB10,BB2]，得到节点BB9'；</li><li>对于BB8，合并[BB8,BB9',BB11',BB2]，得到节点BB8'；</li><li>最后合并[BB7,BB8',BB2]，得到最后的节点BB7；如图(b)所示。</li></ol><h3 id="tail-duplication">Tail duplication</h3><p>在上面的例子中，BB3和BB6是无法被if-converted的（比如包含一个不能进行if转换的函数调用）。我们知道if-conversion必须要在只有一个入口的区域进行，现在BB2和BB5都有入口。那么怎么继续合并呢？可以采用TailDuplication技术。</p><p>对于一个基本块构成的区域R，它具有一个entry和别的基本块<spanclass="math inline">\(B_i\)</span>，且这些基本块都可以由entry达到。有一些基本块<spanclass="math inline">\(B_s\)</span>存在一些前驱<spanclass="math inline">\(out_1,\dots,out_m\)</span>，他们不在区域R内（这个<spanclass="math inline">\(B_s\)</span>基本块也不一定在R内）。可以使用Tailduplication：</p><ol type="1"><li>对所有<span class="math inline">\(B_s\)</span>可达到的基本块<spanclass="math inline">\(B_j\)</span>（包括<spanclass="math inline">\(B_s\)</span>）进行一个复制<spanclass="math inline">\(B_j&#39;\)</span>；</li><li>被复制<span class="math inline">\(B_j\)</span>的所有后继<spanclass="math inline">\(B_k\)</span>也一起被复制；</li><li>把<span class="math inline">\(out_k\)</span>全部转移到<spanclass="math inline">\(B_s&#39;\)</span>上。</li></ol><p>在上图(c)的例子中，entry=BB2，Bs=BB5，out=BB3。这样子复制的基本块包括[BB5,BB7]。这样子之后，灰色区域中的基本块，除了BB2就没有别的入边了。就可以进行正常的合并了。</p><h2 id="if-conversion带来的收益">if-conversion带来的收益</h2><p>if-conversion的路径融合具有好处和坏处：语句可以并行执行，但数据依赖会带来寄存器更多的使用，可能超出硬件的限制。我们要对合并前后的基本块进行cost评估。</p><p>假设有两条路径从head出发，如下图所示。分别是<spanclass="math inline">\(path_p=[head,B_1,exit]\)</span>和<spanclass="math inline">\(path_{p&#39;}=[head,B_1&#39;,B_2&#39;,exit]\)</span>，他们被执行的可能性probability是<spanclass="math inline">\(prob(p)\)</span>和<spanclass="math inline">\(prob(p&#39;)\)</span>。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-08-15-25-16.png"alt="Φ消除过程的收益计算" /><figcaption aria-hidden="true">Φ消除过程的收益计算</figcaption></figure><p>对于一个路径<spanclass="math inline">\(P_q=[B_0,\dots,B_n]\)</span>，它的代价cost是</p><p><span class="math display">\[\widehat{P_q}=prob(q)\times \sum_{i=0}^{n-1}(\widehat{[B_i,B_{i+1}]})\]</span></p><p>其中<spanclass="math inline">\(\widehat{[B_i,B_{i+1}]}\)</span>的定义放下英文原文可能更为合适：</p><blockquote><p><span class="math inline">\(\widehat{[B_i,B_{i+1}]}\)</span>represents the cost of basic block <spanclass="math inline">\(\widehat{[B_i]}\)</span> estimated using itsschedule height plus the branch latency br_lat, if the edge <spanclass="math inline">\((B_i, B_i+1)\)</span> corresponds to a conditionalbranch, 0 otherwise.</p></blockquote><p>如果一个带有分支的基本块<spanclass="math inline">\(B_i\)</span>成功了去路径<spanclass="math inline">\(S_q\)</span>，失败了去路径<spanclass="math inline">\(S_{q&#39;}\)</span>，那么它的代价<spanclass="math inline">\(\widehat{B_i}\)</span>为：</p><p><span class="math display">\[\widehat{B_i}=prob(q)\times \widehat{B_i,S_q} + prob(q&#39;)\times\widehat{B_i,S_{q&#39;}} = \widehat{[B_i]}+prob(q)\times br\_lat\]</span></p><p>那么，对于路径<spanclass="math inline">\(path_p=[head,B_1,\dots,B_n,exit]\)</span>和<spanclass="math inline">\(path_{p&#39;}=[head,B_1&#39;,\dots,B_m&#39;,exit]\)</span>，这一部分控制流的原始代价为：</p><p><span class="math display">\[cost_{control}=\widehat{path_p}+\widehat{path_{p&#39;}}=\widehat{[head]}+prob(p)\times(br\_lat + \sum_{i=0}^{n}(\widehat{[B_i]})) + prob(p&#39;)\times\sum_{i=0}^{m}(\widehat{[B_i]})\]</span></p><p>而在if-conversion之后，可以得到下面的代价。其中符号<spanclass="math inline">\(\circ\)</span>是复合函数，将基本块合并在一起，删除相关的分支，并创建谓词操作。</p><p><span class="math display">\[cost_{predicated}=[head \circ B_1 \circ \dots \circ B_n \circ B_1&#39;\circ \dots \circ B_m&#39;]\]</span></p><h3 id="例子">例子</h3><p>对于下图中的例子，存在三条路径。在合并之前的代价为<spanclass="math inline">\(\widehat{path_{p\wedge q}}+\widehat{path_{p\wedge\bar{q}}}+\widehat{path_{\bar{p}}}\)</span>，简化之后即为：</p><p><span class="math display">\[cost_{control}=\widehat{head}+\widehat{side}=\widehat{[head]}+prob(p)\times(1+prob(q)) \times br\_lat\]</span></p><p>合并之后的代价为：</p><p><span class="math display">\[cost_{predicated}=[head \circ side]=\widehat{[head \circside]}+prob(p)\times prob(q) \times br\_lat\]</span></p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-11-2022-05-08-16-01-31.png"alt="复合谓词合并的例子" /><figcaption aria-hidden="true">复合谓词合并的例子</figcaption></figure><p>如果对于<span class="math inline">\(prob(p)\ll1\)</span>，上面的合并方式可能是没有好处的。在这种情况下，将评估其他的策略，比如在exit块之前进行一个路径复制。</p><p>这种以“最大化运行速度”为目标的costfunction需要结合硬件来考虑指令延迟、资源使用和调度约束等参数，此外分支概率可以通过静态分支预测启发式、配置文件信息或用户插入指令获得。这种启发式方法可能是悲观的，因为它没有考虑到由删除分支或显式的新依赖引入的新的优化机会。</p><p>但是，也可能是乐观的，因为它能够优化因为错误的寄存器压力估计，导致寄存器在关键路径上spilling。这样的SSA增量if-conversion算法将合并与否决策的考虑的范围缩小到CFG的局部部分，使得能够非常快地进行计算。此外，if-conversion过程引入的所有指令，比如新的谓词合并指令，或新的临时伪寄存器，都可以考虑在代价函数的计算过程中。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 10. 基于SSA的Instruction Selection</title>
    <link href="/2022/05/06/ssa-book-10/"/>
    <url>/2022/05/06/ssa-book-10/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--10.-基于ssa的instruction-selection">《SSA Book》- 10.基于SSA的Instruction Selection</h1><p>来到了Register Allocation的姐妹篇，InstructionSelection，该步骤将与机器无关中间表示（IR）表示转换为低级中间表示（LIR）或特定目标体系结构的机器代码（MC）。这个过程中往往有多个选择，我们不仅要保证不改变代码原意，还要尽可能选择代价低的指令。</p><p>常用的方式使用data-flowtree（DFT），其基本思想是使用具有代价的语法来描述目标指令集，算法寻找能覆盖DFT中所有指令的最小成本的语句集合。下图就是一个例子，左图是不同的语法和代价，右图是示例DFT。如果我们选择R3，R4，R10来覆盖DFT时，仅需要1的代价。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-10-2022-05-06-22-58-35.png"alt="DFT和具有cost的规则语法的例子" /><figcaptionaria-hidden="true">DFT和具有cost的规则语法的例子</figcaption></figure><p>但是，DFT的大小会限制指令选择。我们利用SSA图来解决这个问题。SSA图可以描述超越基本块边界的非循环和循环信息流，而传统的方法只能对于单个基本块进行分析；其次，SSA图在现代编译器中使用的非常多；而且SSA图中不存在输出依赖或反依赖。</p><p>对于SSA图，我们要介绍的是一个动态规划算法：quadratic mathematicalprogrammingproblem（PBQP）。下图展示了一个程序和其对应的SSA图，不同的颜色表示他们来自不同的基本块。在这种情况下，能够更方便地进行一些跨基本块的优化，比如进行乘法会导致长度为1的浮点操作数变成长度为2的浮点结果，再次进行计算需要进行移位操作。如果将一些移位操作从循环之中放到ret基本块，就可以有更低的代价。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-10-2022-05-06-23-29-43.png"alt="对SSA图进行指令选择的例子" /><figcaption aria-hidden="true">对SSA图进行指令选择的例子</figcaption></figure><p>下面，我们将解释如何用PBQP在SSA图上执行指令选择。</p><h2 id="ssa-tree上的instruction-selection">SSA-tree上的Instructionselection</h2><h3 id="pbqp的问题建模">PBQP的问题建模</h3><p>考虑变量集合<spanclass="math inline">\(X=\{x_1,\dots,x_n\}\)</span>和每个变量对应的有限域<spanclass="math inline">\(\{D_1,\dots,D_n\}\)</span>，PBQP要做的就是为每一个变量<spanclass="math inline">\(x_i\)</span>选择一个策略<spanclass="math inline">\(d\in D_i\)</span>。其中对策略的代价有两种：</p><ol type="1"><li>将变量<span class="math inline">\(x_i\)</span>赋值给<spanclass="math inline">\(D_i\)</span>中的元素<spanclass="math inline">\(d_i\)</span>，分配的代价是局部代价函数<spanclass="math inline">\(c(x_i,d_i)\)</span>;</li><li>将两个相关变量<span class="math inline">\(x_i\)</span>和<spanclass="math inline">\(x_j\)</span>赋值给元素<spanclass="math inline">\(d_i\in D_i\)</span>和<spanclass="math inline">\(d_j\in D_j\)</span>，分配的代价是相关代价函数<spanclass="math inline">\(C(x_i,x_j,d_i,d_j)\)</span>。</li></ol><p>对于一个策略h，它的总代价如下。PBQP问题寻求使得总代价最小化的对所有变量的策略。</p><p><span class="math display">\[f=\sum_{1\le i \le n}c(x_i, h(x_i))+\sum_{1\le i &lt; j \len}C(x_i,x_j,h(x_i),h(x_j))\]</span></p><p>对于不同策略的代价，我们使用向量和矩阵对代价进行存储。一个PBQP问题有结构图<spanclass="math inline">\(G =(V,E,C,c)\)</span>，我们称之为PBQP图。每个变量<spanclass="math inline">\(x_i\)</span>有对应的<spanclass="math inline">\(v_i\in V\)</span>，<spanclass="math inline">\(e=(v_i,v_j)\inE\)</span>表示了存在相关性的变量集合。<spanclass="math inline">\(C\)</span>和<spanclass="math inline">\(c\)</span>表示了节点和边对应的代价。</p><p>一般来说，上面这个最优化问题是NP困难的。然而，对于许多实际情况，PBQP中的代价图是稀疏的。因此，最优或接近最优的解决方案往往可以在合理的时间限制内找到。</p><p>目前，PBQP使用了“polynomial-time heuristicalgorithm”和“branch-&amp;-bound basedalgorithm”，这使得求解过程的时间复杂度为<spanclass="math inline">\(O(nm^3)\)</span>，其中n为变量的个数，m为有限域元素的最大个数，即<spanclass="math inline">\(m =max(|D_1|,\dots,|D_n|)\)</span>。这个求到的解一般不是最优的，可以使用branch-&amp;-bound技术获得最优解。这些都有现有的工具了，我们只需要对指令选择过程进行建模。</p><h3 id="使用pbqp进行指令选择">使用PBQP进行指令选择</h3><p>首先需要对覆盖使用的规则进行标准化，所有的规则都变转化为baserule和chain rule的形式。其中base rule形如<spanclass="math inline">\(nt_0\leftarrowOP(nt_1,\dots,nt_{k_p})\)</span>，<spanclass="math inline">\(nt_i\)</span>是非终结符，OP是终结符号。chainrule则是无OP的形式<span class="math inline">\(nt_0\leftarrownt_1\)</span>。</p><p>下面是一个PBQP问题的实例，其中语法已经被规范化。其中SHL节点可以采用R4，R5，R6策略，对应的代价被保存在了SHL向量中。在SHL和ADD之间，只有相同存储类型之间可以传递数据（cost=0），不同类型不能传递（cost=∞），这个关系通过矩阵显示出来。最后，所有被标红的点值即为每一个节点选择的策略，总代价最小。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-10-2022-05-07-11-04-25.png"alt="语法被规范化后的PBQP实例" /><figcaption aria-hidden="true">语法被规范化后的PBQP实例</figcaption></figure><h2 id="算法推广">算法推广</h2><p>上面的算法对于某些复杂的语句无能为力，比如不支持带有多个结果的机器指令。比如下面的例子中，许多体系结构都有某种形式的自动增量寻址模式。在这样的机器上，对p和q的load和inc操作都可以在一条指令中完成，这对代码大小和性能都有好处。然而，这种“post-incrementloads”操作，不能使用单一的树形模式建模。它产生多个结果，将跨越SSA图中的两个不相邻节点，这个不能用以前一个操作对应一个节点的方式对应了。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-10-2022-05-07-13-06-14.png"alt="一个具有循环依赖的复杂操作集合" /><figcaptionaria-hidden="true">一个具有循环依赖的复杂操作集合</figcaption></figure><p>我们对这种复杂的操作进行建模，首先对于原始的操作模型：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C++">P1: tmt &lt;- <span class="hljs-built_in">ST</span>(x:reg, reg), reg &lt;- <span class="hljs-built_in">INC</span>(x) : <span class="hljs-number">3</span><br>P2: stmt &lt;- <span class="hljs-built_in">ST</span>(reg, reg) : <span class="hljs-number">2</span><br>P3: reg &lt;- <span class="hljs-built_in">INC</span>(x) : <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>将其中的复杂操作P1分解为两个单独的标准操作，另外两个单独操作不变：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++">P1<span class="hljs-number">.1</span>: stmt &lt;- <span class="hljs-built_in">ST</span>(reg, reg) : M<br>P2: stmt &lt;- <span class="hljs-built_in">ST</span>(reg, reg) : <span class="hljs-number">2</span><br>P1<span class="hljs-number">.2</span>: reg &lt;- <span class="hljs-built_in">INC</span>(x) : M<br>P3: reg &lt;- <span class="hljs-built_in">INC</span>(x) : <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>对于我们的建模，将为复杂操作的每个实例创建新的临时变量。这个变量记录该实例是否使用复杂操作，其由on和off元素组成。下图中的节点1-6为原始的操作节点，而节点7-9即为新的临时变量。假设当节点7选用on2时，则说明p+1与*p将会使用一条指令完成，其中on2的代价k=3-2M，M是一个很大的整数值，这样可以保证“要么选取P2、P3、off，要么同时选取P1子操作以及on”。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-10-2022-05-07-13-44-32.png"alt="包含复杂操作的PBQP图的示例" /><figcaption aria-hidden="true">包含复杂操作的PBQP图的示例</figcaption></figure><p>但是，p+1和*p的同时执行将会影响到操作之间的依赖关系。考虑节点7和节点8之间建立的矩阵。假设节点7在选择了on2，那么对于节点8只剩下两种选择：选择off，或映射到on3。这是因为节点7对应的是寄存器p，节点8对应的是寄存器q，而q的store语句的执行依赖于p的累加，即节点7必须先于8执行。这些依赖关系就在矩阵中使用∞和0来区分。</p><p>基于上述考虑，最终选择的即为标为红色的策略。变量p和q使用复杂指令，变量r仍然使用普通简单指令，总代价为8。</p><h2 id="总结">总结</h2><p>InstructionSelection问题是通过使用SSA图实现的。通过SSA能考虑整个流程，而不只考虑局部一部分（类似窥孔优化那种）。只要对问题进行了建模，就可以用免费的PBQP库进行求解，LLVM就包含了这个库。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
      <tag>Instruction Selection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 9. 基于SSA的Register Allocation - Assignment</title>
    <link href="/2022/05/03/ssa-book-9/"/>
    <url>/2022/05/03/ssa-book-9/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--9.-基于ssa的register-allocation---assignment">《SSABook》- 9. 基于SSA的Register Allocation - Assignment</h1><p>上一节讲了RA中的spilling，在这一个图染色的过程中，我们的输入是一个在程序各个点最大活跃变量数量都小于寄存器数量的程序。在这个程序上，我们需要为不同的寄存器进行染色。</p><h2 id="贪婪的着色方案">贪婪的着色方案</h2><p>考虑图中的一个节点的度为R-1，其中R为寄存器数量，那么这个寄存器的颜色其实就已经确定了，必定只有一个颜色是可用的了。这些节点可以被<strong>简化</strong>。我们可以将这个节点放到栈中，并重复进行这个过程。如果图会变成一个空图，那么就说明这个图可以以R色染色。这个就叫做<strong>贪婪的着色方案</strong>。</p><p>首先我们要对图进行简化，使得原书中给出了Simplify(G)算法，G为输入的无向图。算法一个一个移除节点，并把移除的节点放到stack之中，把度小于R的节点放置到worklist之中。如果结束时worklist不为空，则说明该图无法被R色着色。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-9-2022-05-03-16-04-37.png"alt="使用贪心着色方案来创建stack" /><figcaption aria-hidden="true">使用贪心着色方案来创建stack</figcaption></figure><p>对于得到的stack，使用下面的算法进行着色。这个过程其实就很简单了，尽可能地选择可行的颜色即可：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-9-2022-05-03-16-28-08.png"alt="使用贪心着色方案的着色部分" /><figcaption aria-hidden="true">使用贪心着色方案的着色部分</figcaption></figure><h3id="一些关于ssa形式下的算法的讨论">一些关于SSA形式下的算法的讨论</h3><p>如果对传统的代码形式下得到的干涉图使用上面的算法，即便输入是一个度小于R的图，图本身仍然不一定是可R色着色的。这样将会导致着色阶段的失败，进而使得无法将spilling和assignment阶段很好地区分开来。但是，对于SSA图，就不可能出现这种着色过程卡住的情况了。这里的解释我是从FernandoMagno的《SSA-BASED REGISTER ALLOCATION》PPT中找来的，进行了一个简单的陈述，简单的解释过程大概是：</p><ol type="1"><li>对于SSA图，在支配图中画出def-use关系构成的干涉图，和原有CFG下的干涉图是一样的；</li><li>在树结构上构建出的干涉图是弦图（chordal graph）；</li><li>弦图的性质：一个图是弦图当且仅当其有完美消除序列；</li><li>完美消除序列：一个包含所有结点的序列，对与序列中的点vi，排在vi之前并且和vi相连的点是一个团（团中的任何节点两两相连）；</li><li>如果我们按照完美消除序列进行上色，当上色上到第n个节点v时，v的邻接节点就是一个被上色完成的团。团中的任意两两节点都是互联的，所以肯定使用了和团点数一样的颜色。因此，如果节点v有M个邻接节点，那么v的颜色即为M+1。</li></ol><p>经过上面的分析，对于一个度小于R的图，在着色过程中的最大团一定小于R，因此颜色必然是够用的。</p><blockquote><p>那个PPT还讲了蛮多东西的，如果有时间可以专门为PPT写一个文章~</p></blockquote><h2 id="ssa下的染色后合并coalescing">SSA下的染色后合并Coalescing</h2><p>这一步是为了减少从寄存器到寄存器之间的无意义move操作。这种无意义操作可能因为一些优化过程，或者Φ函数的析构导致。我们需要评估合并一些寄存器之后可以得到的好处，以及我们可以节省多少指令。</p><h3 id="基于图染色的合并方法">基于图染色的合并方法</h3><p>分为两种，激进的合并方式和保守的合并方法：积极合并互相没有干涉的节点时，不考虑结果图的颜色数；而在保守合并中，颜色数不能增加。</p><p>这两种合并方法都是NP完全的，在目前的讨论下我们将专注于保守合并方案，因为我们不希望去处理更多的spill。工具IteratedRegisterCoalescing（IRC）使用了增量的合并方法，包含下面两种策略。其中度小于R的节点称为低度节点，而其他节点称为高度节点。</p><ol type="1"><li>Briggs：如果得到的节点有少于R个高度邻接节点，合并u和v。因为这个合并后的节点在其低度邻接节点被简化后，这个节点始终可以被简化，因此图将保持贪婪R色可着色；</li><li>George：如果u的所有高度邻接节点也是v的邻接节点，合并u和v。合并之后，一旦所有的低度邻接节点都被简化后，就得到了原始图的一个子图，因此图也将保持贪婪R色可着色。</li></ol><p>下面的算法展示了一个简化版本的IRC合并算法，它将合并和简化合并到一起进行：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-9-2022-05-04-13-54-52.png"alt="IRC的剪枝版本，忽略了spill，仅考虑着色和合并" /><figcaptionaria-hidden="true">IRC的剪枝版本，忽略了spill，仅考虑着色和合并</figcaption></figure><p>简单来说，它以以下三个过程工作：</p><ol type="1"><li>尽可能简化not move-related（no affinity）的低度节点；</li><li>当没有更多的节点可以通过这种方式简化时，将选择一个affinity。如果两个规则（Briggs或George）中的一个成功，则相应的节点被合并。如果不是，则删除这个affinity；</li><li>重复进行上述2个步骤，直到图为空。</li></ol><p>这里其实讲的很草率啊，我也看得不是很明白。在《SSA-BASED REGISTERALLOCATION》中也有讲到合并部分，到时候看再讲讲吧。</p><h3 id="基于扫描的合并方法">基于扫描的合并方法</h3><p>回顾上一章的Tree-scan策略，假设当前程序点p是一条从变量v到v'的mov指令，在第3行释放v时对应的颜色，可以在第五行的v'分配颜色时重复使用。这是最基本的合并思想。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-13-10-28.png"alt="Tree-scan策略" /><figcaption aria-hidden="true">Tree-scan策略</figcaption></figure><p>但是这种方法对Φ函数却无能为力。对于来自不同前驱基本块x1，x2在基本块开头给到x3的值，我们的寄存器分配算法通常只能合并其中两个变量，而不会自动把三个都使用一个寄存器。</p><blockquote><p>TODO：关于这个问题，原书建议使用第21章“SSA Destruction for MachineCode”解决，但是我没看过……</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
      <tag>Register Allocation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 8. 基于SSA的Register Allocation - Spilling</title>
    <link href="/2022/05/01/ssa-book-8/"/>
    <url>/2022/05/01/ssa-book-8/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--8.-基于ssa的register-allocation---spilling">《SSABook》- 8. 基于SSA的Register Allocation - Spilling</h1><p>这是对应原书高级部分的第22章，因为觉得好重要，所以先跳到这里。寄存器分配需要考虑的问题有三个：</p><ol type="1"><li>有足够的寄存器给所有的变量吗？（spill test）</li><li>如果是，选择哪个寄存器分配给哪个变量？（assignment）</li><li>如果没有，我如何选择哪些变量暂存到内存？（spilling）</li></ol><p>整体来说，最需要考虑的问题是Spilling和Assignment的方法。两个部分都较为复杂，因此分为两篇文章来描述。这篇文章讲的则是寄存器分配算法的总览，以及Spilling部分。</p><h2 id="典型的寄存器分配算法类型">典型的寄存器分配算法类型</h2><p>首先，需要考虑两种经典的分析方法：线性扫描和图染色方法。</p><p><strong>线性扫描</strong>：线性扫描的方法以拓扑排序的方式依次遍历每个基本块，把变量def最晚的use之间的区域都视作变量的live区间。当遇到变量的定义时，我们检查是否有空闲的寄存器，如果成功（spilltest），我们选择一个寄存器存放该变量（assignment）。如果没有，我们从当前存在的变量中选择使用最广泛的变量，将其溢出（spilling）。当我们遇到它的最后一次使用时，我们释放分配给它的寄存器。这样子有较高的效率，但是精度较低（因为有很多基本块不会被执行）。</p><p><strong>图染色寄存器分配方法</strong>：基于图染色的寄存器分配方法，为基本块之间构造干涉图（Interferencegraph），分配器将尝试给干涉图着色，如果成功（spilltest），那么着色则表示了寄存器对变量的有效分配结果（assignment）。如果不是，分配器将选择一些节点（通常是链接的节点数量最多的节点），并使用内存暂存（spilling）将它们从图中删除。虽然图染色能够提供更精确的分析，但它是np完全问题。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-12-26-26.png"alt="线性扫描和图染色方法" /><figcaption aria-hidden="true">线性扫描和图染色方法</figcaption></figure><p>在SSA下的变量的use都是被它的def支配的（应该是指严格SSA，因为编译器构造出来的SSA一般都是严格的），因此，SSA中活跃范围都是树形的，而不会出现“在某个基本快中合并”的情况，因为这些合并都被Φ函数创建新变量给终结了。下图即为SSA形势下的活动范围和传统的区别：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-12-47-40.png"alt="SSA形式下的变量活动范围" /><figcaption aria-hidden="true">SSA形式下的变量活动范围</figcaption></figure><p>这个特性带来了一些好处。在SSA下，基于图的分配方法中的干涉图变成了弦图，这意味着可以在图着色的过程，使用一些简单算法。这个在后面进行介绍。</p><p>对于线性扫描策略，在SSA下可以进行优化版本的Tree-scan树扫描策略。这种基于贪婪的分配会扫描<strong>支配树</strong>（而不是原始的CFG），按照自上而下的顺序从根到叶给变量着色，分配寄存器。因为树的分支是独立的，所以对一个分支着色不会对树的其他分支产生影响。树扫描策略的伪代码如下所示。简单来说，当到达变量最后一个use时，这个颜色变得可用；当到达变量的定义时，为它选择一个颜色即可。然后到达基本块末尾时，就以BFS为每一个子节点调用该函数。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-13-10-28.png"alt="Tree-scan策略" /><figcaption aria-hidden="true">Tree-scan策略</figcaption></figure><p>无论是树扫描还是图染色，我们使用的方法都是首先把同时live的最大变量数量降低至寄存器数量R以下，然后再为它进行染色。这样就可以把assignment步骤和spilling步骤分开。下面我们对Spill步骤进行介绍。</p><h2 id="spilling溢出">Spilling：溢出</h2><p>溢出过程对于线性扫描和图染色是不同的。对于线性扫描，它的分析是局部的，当遍历到程序的某个节点，发现活跃变量数量超过了寄存器上限时，算法将会对这一个小范围进行spill，也就是添加load和store操作将数据写回。这个过程是局部性的。但是，图染色使用了干涉图，这是一个全局性的概念。图染色的溢出意味着直接删除干涉图的一个节点，从而删除变量的整个生命范围。在每次使用这个变量时，都会从内存读取这个变量。</p><p>图染色的这种方法叫做Spilleverywhere的策略。spill的过程中需要用寄存器暂存load和store的数据，这些寄存器同样需要寄存器分配。因此，需要迭代进行寄存器分配过程，干涉图将重新构建。</p><p>选择什么样的变量进行spill本质上是一个优化问题，我们的目标是：结果代码应该是可用R个寄存器着色的，且插入的load-store的代价应该是最小的。</p><h2 id="graph-based的spill策略">Graph-based的spill策略</h2><p>对于需要spill的节点选取，如果我们需要全局的考虑哪些变量需要spill，这个过程会是一个NP问题。因此这里使用基于贪婪的costfunction。最简单的代价即为“节点的度”，优先写回度最高的节点即可。但是，只考虑节点的度是脱离了CFG本身的，所以我们要考虑更多的因素。</p><p><strong>“useful”标签</strong>：这个属性表示了“在变量的生命周期中，同时活跃的变量超过寄存器数R的程序点数量”。对于这个属性的计算，需要在自底向上遍历CFG的过程中同时计算考虑两个元素：</p><ol type="1"><li>对于每个程序点p，计算p.pressure，对应于p的定义点上活着的变量数量；</li><li>对于变量v，具有(v→p).high的布尔值属性。标明这个程序点p有v的活跃，如果该值为true，则表明程序点的活跃变量数量大于寄存器数量。</li></ol><p>那么，useful标签的定义即为下式。如果v.useful=0，则说明对该变量进行spill是没有意义的。</p><p><span class="math display">\[v.useful = |\{p:(v\to p)  \wedge p.pressure &gt; R \}|\]</span></p><h2 id="scan-based的spill策略">Scan-based的spill策略</h2><p>上面基于图的方法太过于全局，往往无法取得很好的效果。所以更好的就是Scan-based的方法。基于扫描的方法能够更局部性的将变量写回到内存中，取得更高的寄存器利用率。</p><p>下面给出了一个分配的算法。简单来说，对于每一个基本块B，都有一个B.in_regs集合，这个集合里面的变量就是要被放在寄存器中的变量。如果use的变量不在in_regs中，那么就需要把他load出来，并把这个v放到in_regs中，接着使用<strong>evict函数换下去一个变量</strong>。此外，对于last_used的，要把它从in_regs中删除；新def的变量，需要添加到in_regs中，同时也要调用evict换走一个变量。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-18-32-11.png"alt="Furthest first spilling算法" /><figcaption aria-hidden="true">Furthest first spilling算法</figcaption></figure><p>这些过程是很直观的，最重要的就是我们根据什么来选择需要spill走的变量，也就是evict函数的实现。接下来，我们讨论的方法是“Furthestfirst”。当evict函数被调用时，我们将会把“下一次use隔得最远”的变量spill。</p><h3 id="基于distance属性的furthest-first策略">基于Distance属性的Furthestfirst策略</h3><p>下面的函数展示了基于Distance属性的evict函数实现。如果in_regs中的变量已经超过最大寄存器数量了，那么就把最大的distance的变量换出去，并且相应地添加store操作。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-18-35-03.png"alt="基于distance属性的evict函数实现" /><figcaptionaria-hidden="true">基于distance属性的evict函数实现</figcaption></figure><p>下面给出一个实际的控制流图例子。其中，程序点p0，p3和p4寄存器压力过高，需要选取变量spill。假设左边的分支被选取，且循环执行100次，那么x的“下次use的距离”将会达到101，非常远。假设右边的分支被选取，那么变量y的下次use距离为2，相对更远一些。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-15-46-37.png"alt="选取变量进行spill的例子" /><figcaption aria-hidden="true">选取变量进行spill的例子</figcaption></figure><p>如果我们考虑压力高的程序点，左边的路径并没有寄存器压力过高的程序点，因此选取x进行spill只会优化p0的压力。反之，如果选取y，就能优化p0，p3和p4的压力。因此，最后的结果优先选择y作为spill变量。</p><p>但是，假设p1也是一个压力过高的程序点，那么这个时候spillx就变得必要了，不然要存取100次变量y……</p><p>综上所述，“distance”的概念是不够准确的。我们将用“profitability”的概念替换第一个最远算法中的“distance”概念。也就是对“能够受益于spill某个变量的程序点”数量的度量。</p><h3id="使用profitability代替distance">使用profitability代替distance</h3><p>设p是一个程序点，v是p处活跃的变量。设v.HP(p)（High-Pressure）是所有程序点q的集合满足：</p><ol type="1"><li>在q处的寄存器压力大于R；</li><li>v在q处是live的；</li><li>存在一条从p到q的路径，它不包含v的任何use或者def。</li></ol><p>那么，spill v带来的profitability则为：</p><p><span class="math display">\[v.spill_profitability(p)=\sum_{q\in v.HP(p)}q.frequency\]</span></p><p>在之前的例子中，x.HP(p0)即为在p0处spillx受益的程序点的集合。下面的表格给出了我们的实例在两个场景下的不同变量的情况。在p1不是寄存器高压力点的情况下，我们会选择y；反之我们会选择x。</p><table><thead><tr class="header"><th></th><th>p1寄存器压力低</th><th>p1寄存器压力高</th></tr></thead><tbody><tr class="odd"><td>x.HP(p0)</td><td>{p0}</td><td>{p0,p1}</td></tr><tr class="even"><td>y.HP(p0)</td><td>{p0,p3}</td><td>{p0,p3}</td></tr><tr class="odd"><td>x.spill_profitability(p0)</td><td>1</td><td>51</td></tr><tr class="even"><td>y.spill_profitability(p0)</td><td>1.5</td><td>1.5</td></tr></tbody></table><h3 id="基本块in_regs属性的初始化">基本块in_regs属性的初始化</h3><h4id="普通基本块的in_regs初始化处理">普通基本块的in_regs初始化处理</h4><p>上面的算法依赖于一个初始化的in_regs，并在这个集合的基础上对变量进行调整，因此我们需要首先计算in_regs的初始化。初始化算法基于拓扑排序，即在分析某个基本块时，它的前驱都已经被处理。那么前驱中的Live-in变量有三种情况：</p><ol type="1"><li>这个变量在所有前驱基本块中都available（allpreds_in_regs）；</li><li>在部分前驱基本块中available（somepreds_in_regs）；</li><li>不在任何前驱基本块中available。</li></ol><p>变量是available的指这个变量已经被存在寄存器中了，还没有被spill出去。那么对这个基本块的B.in_regs计算如下。首先，先把allpreds_in_regs的变量放进去，然后再把部分前驱基本块中available集合中，profitability较小的变量放进去。这样得到最终的in_regs。（这里好像没有讲到如果allpreds_in_regs变量的数量超过上限了该怎么办？但仔细一想，如果allpreds_in_regs超了，那么前驱寄存器保存的变量数量肯定也是超过了的，所以这种allpreds_in_regs超了的情况应该不会发生）。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-16-24-31.png"alt="普通基本块的B.in_regs的初值计算" /><figcaptionaria-hidden="true">普通基本块的B.in_regs的初值计算</figcaption></figure><p>对于那些需要spill的变量，将会添加load操作在对应的前驱块中（或者前驱的criticaledge上）。这个过程和析构Φ函数的过程类似，所以实际过程中一般都会在后期析构SSA的时候顺便把操作给添加了。</p><h4 id="循环头的in_regs初始化处理">循环头的in_regs初始化处理</h4><p>循环的in_regs情况会更加的复杂，和普通基本块中的情况会不一样。下面的例子展示了为循环头计算in_regs的情况：</p><ol type="1"><li><p>例子(a)中，在上面的基本块末尾，假设x不再在寄存器中available（即已经被spill出去了），但是如果我们在p2load回来，那就需要load好多次。所以最好的方法就是添加在p1，也就是另外加一个基本块。那么，B.in_regs中将会包含x（就是下面的那个基本块），这和之前的分析是相反的。</p></li><li><p>对于例子(b)中，假设在循环的入口处x仍然在寄存器中available，在标记为HP的地方寄存器溢出了，我们会在p0存储变量，然后在p2重新load回变量，这样也可以避免在循环内不断地被执行。因此，B.in_regs中将会不包含x，这也和之前的情况相反。</p></li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-18-01-36.png"alt="循环入口的B.in_regs初始值计算例子" /><figcaptionaria-hidden="true">循环入口的B.in_regs初始值计算例子</figcaption></figure><p>所以，对于循环入口处的计算，需要下面的算法。其中，B.livein表示B和L的Live-In变量集合，L.Maxlive是指整个循环中需要寄存器最多的数量，而R是指寄存器的总数。如果L.Maxlive＞R，则必须要溢出L.Maxlive−R个变量，这些变量是具有最小profitability代价的变量。所以，不超过|B.livein|−(L.Maxlive−R)个变量将会在B中被分配至寄存器中，其他的变量都会被spill出去。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-8-2022-05-02-18-19-35.png"alt="循环入口基本块的B.in_regs的初值计算" /><figcaptionaria-hidden="true">循环入口基本块的B.in_regs的初值计算</figcaption></figure><h3 id="对scan-based的spill算法总结">对Scan-based的spill算法总结</h3><p>讲了这么多奇奇怪怪的东西，spill的整体算法包括几个阶段：首先，我们预先计算live-range和profitability的指标；然后，我们按照拓扑顺序遍历CFG，计算所有基本块B.in_regs的初始值。接着扫描每个基本块。在此阶段，我们在基本块边界维护寄存器和内存中可用的活动变量集，并对in_regs集合进行更新。最后，在分析的过程中，为代码添加load和store操作。</p><blockquote><p>好多，写的累死我了，下一次更新assignment部分！</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
      <tag>Register Allocation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 7. 基于SSA的Liveness Analysis</title>
    <link href="/2022/04/28/ssa-book-7/"/>
    <url>/2022/04/28/ssa-book-7/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--7.-基于ssa的liveness-analysis">《SSA Book》- 7.基于SSA的Liveness Analysis</h1><p>本章要介绍的是活跃变量分析（Live analysis）。活跃变量的定义为：</p><blockquote><p>对于变量v和程序点p，如果在CFG中沿着从p开始的某条路径会引用变量v在p点的值，则称变量v在点p是活跃（live）的，否则称变量x在点p不活跃（dead）。</p></blockquote><p>字面意思即为这个变量如果在这一个点后还会被使用，那么它就是活跃的。活跃变量分析地结果将会在冗余消除，if-conversion，以及寄存器分配等多个算法中得到运用。活跃变量分析的结果是每一个基本块的开头有多少活跃变量，结尾处有多少活跃变量。</p><h2 id="基于数据流的活跃变量分析">基于数据流的活跃变量分析</h2><p>首先，在SSA形式下的控制流图的活跃分析中，对于一个可规约CFG，一个变量v具有以下两个规则：</p><ol type="1"><li>v在位置q是活跃的，当且仅当v在“包含位置q但不包含v的定义”的最大的循环/基本块的入口处是活跃的；</li><li>v在位置h是活跃的，当且仅当前向CFG中有一条路径，从h到v的use不不会经过v的定义。</li></ol><p>基于这两个定义，我们可以通过两次遍历得到活跃分析结果。第一次后向地遍历前向CFG，利用规则2判断部分活跃信息，第二次利用loopnesting forest，对活跃信息进行细化。</p><h3 id="可规约图的活跃分析">可规约图的活跃分析</h3><p>首先，数据流分析方程如下所示：</p><p><span class="math display">\[\begin{split}    LiveIn(B) &amp;= PhiDef(B) \cup UpwardExposed(B) \cup(LiveOut(B)/Defs(B))\\    LiveOut(B) &amp;= \bigcup_{S\in succ(B)}(LiveIn(B)/PhiDefs(B))\cupPhiUses(B)\end{split}\]</span></p><p>公式中相对不容易理解的即为UpwardExposed(B)项，该项指代了没有在这个基本块之中被定义的变量，这些变量有一种“他们的定义在更前驱”的感觉hhhh。数据流分析的过程为反向传播，算法如下所示。算法整体以后序遍历的形式展开。首先，所有基本块均被初始化为未访问的，然后对每个基本块利用公式计算LiveOut(B)的值。接着，算法逆序遍历基本块中的语句，将def从Live中去除，将use加入Live中。最后，Φ函数定义的值肯定是在基本块的LiveIn中，得到LiveIn(B)的值，并且将这个Block设置为已访问的。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-04-30-16-25-55.png"alt="基于后序遍历的部分活跃变量分析" /><figcaptionaria-hidden="true">基于后序遍历的部分活跃变量分析</figcaption></figure><p>“是否访问”的属性决定了上面的处理过程不会处理循环的回边。接着，在下一个阶段，算法需要遍历循环森林，对Live信息进行进一步更新。算法如下所示。算法将循环头中的活跃信息，分发至循环内部的其他节点。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-04-30-18-03-58.png"alt="在循环森林中计算活跃变量信息" /><figcaption aria-hidden="true">在循环森林中计算活跃变量信息</figcaption></figure><p>下图展示了一个可规约图的分析过程。在后向传播数据流分析过程中，变量a只在LiveIn(2)和LiveOut(1)处活跃。而在循环森林中，算法将会将基本块3中的活跃信息，从他所在的最大不包含定义的循环头L2向下传播到循环体中的所有块和内部循环，即L3包含的基本块3和4。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-04-30-21-07-54.png"alt="数据流分析的例子" /><figcaption aria-hidden="true">数据流分析的例子</figcaption></figure><h3 id="不可规约图的活跃分析">不可规约图的活跃分析</h3><p>对于不可规约图，我们需要在分析时将其转化为可规约图的形式。对于一个循环，如果循环内某一个基本块变量是活跃的，那么随着循环的执行，在循环的所有节点，该变量都是活跃的。因此，对于一个接入到循环的一条边，我们把这条边连接到别的位置，是不会改变循环内部该变量的活跃情况的。</p><blockquote><p>原书语句：转换后的代码没有与原始代码相同的语义。但是，因为循环是SCC的，支配关系是不变的。由于这个原因，循环L中的任何Live变量，在循环中的任何一个地方都是Live的。因此，将进入的边重定向到循环的另一个节点不会改变变量的Live情况。</p></blockquote><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-04-30-21-38-51.png"alt="由不可约CFG转化而来的可约CFG" /><figcaption aria-hidden="true">由不可约CFG转化而来的可约CFG</figcaption></figure><p>在之前的算法中，其实已经考虑了上述的情况。我们在分析的时候，选择的是循环头而不是Live变量的入口节点。这样使得我们在分析的过程中可以将不可规约循环直接作为可规约循环来看待。比如上图中的图(a)和图(b)，修改了边的位置，并不会使活跃变量分析结果出现变化，算法执行方式也不会变化。</p><h3 id="计算outermost-excluding-loop-ole">计算outermost excluding loop(OLE)</h3><p>在算法执行过程中，需要进行“寻找包含节点a但不包含b的最大循环头”这样的过程，我们需要算法对这个过程进行优化。</p><p>简单的描述这个过程使用的算法。考虑上图(c)的循环，对循环进行编号，循环L2，L5，L8分别对应0，1，2。那么，对于节点9，就可以得到编号101，也就是在循环0和2内；对于节点6，编号110，在循环0和1内。那么包含6而不是9的最外层循环即为110and ~101 = 010，也就是L5。</p><h2id="判断变量v在点q处是否活跃的方法">判断“变量v在点q处是否活跃”的方法</h2><p>如果我们只是需要判断v在某个点的入口和出口是否live，那么不需要利用数据流对所有程序点位置的活跃信息进行计算。首先，设v在CFG节点d=def(v)中定义，设u∈use(v)，假设程序点q由d严格支配（如果不支配的话q就不是live了），我们需要以下两个原则：</p><ol type="1"><li>设h是包含q但不包含d的最大循环的头（如果最大循环不存在，那么就让h=q）。那么在h是live的，当且仅当存在一条从h到u的前向路径（forwardreaching）；</li><li>如果变量v在循环的头部是live，那么它在循环内的任何节点都是live。</li></ol><p>基于上面的内容，可以下面的算法。算法会依次判断：</p><ol type="1"><li>（line5-12）如果q与d在相同的基本块中，那么v在程序点q是live的，当且仅当这个基本块外有一个use，或者在q之后有一个use；</li><li>（line18-19）如果h是一个循环头，那么v在q处是活的，当且仅当一个use可以从h前向到达；</li><li>（line16-17）否则，如果use在与q相同的基本块中，则这个use必须在q之后。</li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-05-01-09-59-57.png"alt="Live-In Check算法" /><figcaption aria-hidden="true">Live-In Check算法</figcaption></figure><p>同样的，还有live-out check算法，与Live-incheck算法的区别仅在于第5、10和16行的比较方式。在第5行，如果q等于d，它不可能是live-in的，而可能是live-out的（当到达程序点的时候肯定不是live的，但是从程序点走的时候可能是live的，如果后面还有别的use的话）；在第11行和第17行中，如果q处于use点，则它可能是live-in的，而不可能是live-out的。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-05-01-10-05-05.png"alt="Live-Out Check算法" /><figcaption aria-hidden="true">Live-Out Check算法</figcaption></figure><h2 id="使用路径探索的live分析">使用路径探索的Live分析</h2><p>还有一种方法就是从use开始，在CFG上往回分析，直到找到这个use对应的def。下面的算法展示了这个过程。对于变量v，对v的use存在的所有block，如果这个use在这个block的后继中的Φ被使用，那么这个block的LiveOut(B)内部一定存在这个v。接着，对于这个blockB，使用Up_and_Mark(B,v)算法，在反向路径上进行更新：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-7-2022-05-01-10-51-14.png"alt="使用类似堆栈数据结构的路径探索" /><figcaptionaria-hidden="true">使用类似堆栈数据结构的路径探索</figcaption></figure><p>算法开始往回走，如果B中就存在这个v的定义，那么直接就可以结束了，之前不可能有Live了。当到了基本块入口处，如果发现LiveIn(B)已经包含变量v了，那么说明这里的分析已经被完成了，就不用继续了。接着，算法将v放入LiveIn(B)中。如果v是在Φ中被定义，就不用继续向前分析了，反之，就在他的前驱基本块中，继续调用该函数向前传播。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 6. 基于SSA的Information Propagating</title>
    <link href="/2022/04/24/ssa-book-6/"/>
    <url>/2022/04/24/ssa-book-6/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--6.-基于ssa的information-propagating">《SSA Book》- 6.基于SSA的Information Propagating</h1><p>从这一节开始，将不再遵循书中的顺序。因为除开之前写过的部分，之后的章节之间相对独立。我就根据自己的兴趣，不断更新吧。</p><p>本节要讲的是基于SSA的稀有条件常数传播（Sparse Data-flowPropagation），这是常量传播算法中的一种，也是目前最常用的一种。这种算法依赖SSA形式，它不仅能够用常量值替换常量变量，还能消除因为常数传播而永远不会发生的分支，同时速度还很快！本章的算法不止能被运用于稀有条件常数传播，只要修改数据流传播函数，对于其他的前向数据流分析同样适用。</p><h2 id="算法流程">算法流程</h2><p>首先，考虑常量传递中数据流传递的方程。常量传播算法采用的格（Lattice）是一个最简单的三层格，T表示尚未确定的值，⊥表示不为常量的值，而中间的多个v则为已知常量值的常量。当两个数据流信息交汇时候，考虑下列情况：</p><ol type="1"><li>如果两个都是常量，且常量值相等，那么交汇结果继续是这个常量；</li><li>如果一个是常量，另一个是T，那么结果为常量；</li><li>如果两个都是T，那么结果为T；</li><li>其他情况，结果都是⊥。</li></ol><p>SSA形式的数据流分析依赖于变量的def-use链，这些信息被提取出来构成了SSAgraph。下图即为一个例程和它的SSAgraph。SSA图的节点对应于程序的操作，边连接了变量的定义和它的所有use。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-6-2022-04-24-22-35-24.png"alt="示例程序及其SSA graph" /><figcaption aria-hidden="true">示例程序及其SSA graph</figcaption></figure><p>接着就是算法介绍。该算法虽然也不算上很复杂，但是涉及对两个列表的数据更新。首先给出算法全貌：</p><p><strong>Step 1.</strong>首先将CFG的所有边设置为executable=0，列表CFGWorkList初始化为CFGstart节点的出边，而 列表SSAWorkList初始化为空。</p><p><strong>Step 2.</strong>任选两个列表其中一个，从顶端各自拿出一个元素。</p><p><strong>Step 3.</strong> 如果拿出的元素是一个CFG中的边，那么：</p><ol type="1"><li>设置executable=1；</li><li>对于这个边目标基本块中的Φ函数，对它调用Visit过程；</li><li>如果目标基本块是第一次被访问，那么对于它的所有操作调用Visit过程；</li><li>如果目标节点只有一个executable=0的输出边，那么将该边附加到CFGWorkList。</li></ol><p><strong>Step 4.</strong> 如果该元素是一个SSA图中的边，那么：</p><ol type="1"><li>如果目标是一个Φ操作，那么对它调用Visit过程；就在这个Φ函数上合并这个操作数的数据流信息；</li><li>对于其他操作，检查CFG中这些操作所在节点的传入边缘的是否executable；如果存在可执行的边缘，那么对它调用Visit过程。</li></ol><p><strong>Step 5.</strong> 重复执行上面的Step2-4，直到两个列表均为空。</p><p>上面的过程中提到的Visit过程如下：</p><ol type="1"><li>根据操作的类型传播数据流信息：<ol type="1"><li>Φ函数：如果Φ函数的某个操作数对应的控制边是executable的，那么就在这个Φ函数上合并这个操作数的数据流信息；</li><li>条件分支：利用数据流分析每个操作数，并判断该条件分支中分析之后无法被执行的边，并把这个边添加到CFGWorkList中；</li><li>普通操作：利用基本的数据流方法传递信息；</li></ol></li><li>在上面更新数据流的过程中，当一个操作的数据流信息发生变化时，将该操作在SSA图中所有出边，都将被附加到SSAWorkList中。</li></ol><!-- ![带有Φ操作和分支常量传递的例子](https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-6-2022-04-25-21-34-15.png) --><p>算法的原理其实很好被理解，在CFG中进行正常的数据流分析，每次更新数据流时借助SSA图边的帮助，即利用def-use边进行数据流分析。每次更新数据流信息，可能更新节点的出边节点的数据流也会受到影响，因此把这些边添加到待处理列表中。直到列表清空，代表没有数据流信息更新了，数据流分析结束。</p><blockquote><p>如果哪天心情好再补个例子吧(*^_^*)，原文中例子挺清楚的，但是要画图展示出来又挺麻烦的。</p></blockquote><h2 id="算法特性与限制">算法特性与限制</h2><h3 id="算法复杂度分析">算法复杂度分析</h3><p>首先对算法的复杂度进行分析，首先SSA图的每一条边至少要处理一次，且被重复更新的最大次数取决于lattice格的高度h。此外CFG中的每一条边最多被处理一次。因此算法的复杂度为Edge(SSA)*h+Edge(CFG)。</p><p>在研究中发现，SSA图大小的规模通常是随程序大小线性扩大的。在实践中，基于SSA的传播引擎优于传统方法。这是由于能沿着SSA的def-use链直接从变量的定义传播到它的使用，而不用为每个基本块的每个语句都保存数据流信息，只需要为每个变量的定义记录一份信息。</p><h3 id="限制">限制</h3><p>因为信息只能在数据的定义和使用之间传播，这限制了一些数据流问题的解决。首先，该算法缺乏“某个点上，这个变量有没有live或者可不可用”的信息。因为基于SSA的分析不是数据流流动的，而是一步到位的从def到了use，这样无法判断在某一个程序点上的数据流信息。</p><p>此外，使用SSA图的数据流分析只能解决正向传播数据流分析问题。由于SSA图的结构，无法像CFG那样简单地反转图中的边进行反向传递。此外，对于正向控制流，φ函数被放置在正向程序的连接点上，而无法捕获反向控制流图中的连接点信息。然而，有基于类似于SSA形式的算法可以处理反向数据流分析，在其他章节会对这个方法进行描述。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 5. SSA的高级构造算法</title>
    <link href="/2022/04/23/ssa-book-5/"/>
    <url>/2022/04/23/ssa-book-5/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--5.-ssa的高级构造算法">《SSA Book》- 5.SSA的高级构造算法</h1><p>在“3.SSA的基本构造算法”中，介绍了构造SSA的基本方法。Φ语句将会被插入至变量定义的支配边界位置，该Φ语句本身也将变成新的定义。本文将会给出关于求解支配边界DF<sup>+</sup>集合的高级算法，包括：</p><ol type="1"><li>基于DJ-grpah构造DF<sup>+</sup>集合的方法；</li><li>基于数据流分析的DF<sup>+</sup>集合构造方法；</li><li>基于Loop Nesting Forest的DF<sup>+</sup>集合构造方法。</li></ol><h2 id="使用dj-grpah构造dfs">使用DJ-grpah构造DF<sup>+</sup>(S)</h2><h3 id="算法原理">算法原理</h3><p>在支配树上加上原有控制流图中剩余的边，即可构成DJ-graph，这些加上去剩余的边即为joinedge（J-edge）。下图给出一个例子，可以发现，所有的J-edge出发点所在层数永远不会大于目标点。我们可以假设存在一个J-edge从8→7，那么则存在路径从3→8→7，那么6将不再支配7，这和现有的支配树是互相矛盾的。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-23-13-52-37.png"alt="DJ-graph的例子" /><figcaption aria-hidden="true">DJ-graph的例子</figcaption></figure><p>对于DJ-graph中的两个节点w和x，若w是x的祖先节点，那么w的支配边界集合DF(w)满足下列公式：</p><p><span class="math display">\[\begin{split}    DF(w) = &amp;\{z|z \in DF(x) \land z.depth \le w.depth \} \cup \\    &amp;\{z&#39;|y \in subtree(w)/subtree(x) \landy\stackrel{J}{\rightarrow}z&#39; \land z&#39;.depth \le w.depth \}\end{split}\]</span></p><p>文字解释上述公式，DF(w)由两个部分组成，一部分是DF(x)中深度不大于w的节点，另一部分是w的子树中不属于x子树部分的节点y的J-edge，且目标的深度不大于w。</p><!-- TODO：为什么这样就成立呢？ --><blockquote><p>TODO：不太理解为什么全部都存在“深度不大于w”的要求呢？</p></blockquote><p>我们以计算DF(3)和DF(8)为例。在简单的构造方法中计算DF(3)时，我们需要遍历所有3支配的节点{3,4,5,6,7,8,9,10}，判断这些节点存不存在不被3所支配的后继，最终得到DF(3)={2}。接着同样的方法将会应用至DF(8)的求解过程。然而，在利用上述公式后，我们可以先计算DF(8)的值，接着直接利用DF(8)的结果，并遍历{3,4,5,6,7}，即可得到DF(3)。这样子有效减少了冗余运算。</p><p>在求解DF<sup>+</sup>(S)的过程中，需要迭代的进行大量节点的DF计算。将上面的公式运用到算法，一次遍历节点便可求解得到DF<sup>+</sup>(S)，避免计算计算DF之间的冗余操作。</p><h3 id="算法实现">算法实现</h3><p>算法在求解DF<sup>+</sup>(S)时，将所有的节点存放至一个“OrderedBucket”顺序桶中。顺序桶可以理解为一个具有N个槽的数组，N为支配树的高度，每个槽存放一个链表的开头，链表上连接了位于这个深度的节点。接着，对于桶中深度最深的点，执行Visit(x)算法。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">for</span> S中的每一个节点x &#123;<br>    InsertNode(x);<br>    x.visited = <span class="hljs-literal">false</span>;<br>&#125;<br><span class="hljs-keyword">while</span> x = 桶中最深节点 &#123;<br>    curr_x = x;<br>    x.visited = <span class="hljs-literal">true</span>;<br>    Visit(x)<br>&#125;<br></code></pre></td></tr></table></figure><p>Visit()算法如下所示，对于每个节点的J-edge边使用传统的DF(x)计算方法，并把不在S中的节点存放到桶中；对于D-edge采用递归的方法，直接获取支配边目标节点的运算结果。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-23-16-00-22.png"alt="过程：Visit(y)" /><figcaption aria-hidden="true">过程：Visit(y)</figcaption></figure><p>下图反映了计算之前控制流图中DF<sup>+</sup>({1,3,4,7})的过程：</p><ol type="1"><li>首先，最深节点的支配边界DF(7)={2}，2被插入到DF<sup>+</sup>中，也被插入至桶中；</li><li>计算节点4，首先J-edge指向的基本块5被插入到DF<sup>+</sup>和桶中；</li><li>类似的分析将会被应用于5和6，这三个节点均不存在D-edge，因此只会添加J-edge至结果中。进行完上述过程之后，DF<sup>+</sup>({1,3,4,7})={2,5,6}，为如图中最右侧的状态；</li><li>接着，需要分析当前最深节点3，节点3的D-edge中只有基本块8没有被visited，因此调用Visit(8)；</li><li>8，9，10均不存在深度低于3的J-edge，因此遍历节点8以及8的子树，并没有新节点加入DF<sup>+</sup>之中；</li><li>最终，遍历节点2和1时，不存在J-edge和没有visit的D-edge，遍历结束。结果为DF<sup>+</sup>({1,3,4,7})={2,5,6}</li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-24-12-51-42.png"alt="使用算法计算DF+({1,3,4,7})的过程" /><figcaptionaria-hidden="true">使用算法计算DF<sup>+</sup>({1,3,4,7})的过程</figcaption></figure><h2 id="使用数据流计算构造dfs">使用数据流计算构造DF<sup>+</sup>(S)</h2><p>数据流分析的几个关键元素如下所示：</p><ol type="1"><li>初始化：对DJ图中的每一个节点x，初始化DF<sup>+</sup>(x)={}；</li><li>遍历方法：前向遍历，基于BFS从根节点开始遍历；</li><li>数据流传递公式：对于J-edge y→z，那么对于所有满足“x domy且x.depth≥z.depth”节点x，满足：<spanclass="math inline">\(DF^+(x)=DF^+(x)\cup DF^+(z)\cup\{z\}\)</span>；</li><li>不一致条件（即需要继续数据流分析的条件）：对于J-edgey→z，y不满足<span class="math inline">\(DF^+(z) \subsetDF^+(y)\)</span>，则y为不一致的。</li></ol><p>基于上述这些条件，可以得到数据流分析算法。外部函数重复调用该函数，直到该函数返回值为false时停止。结果将会得到每一个节点x的DF<sup>+</sup>(x)集合。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-24-12-15-24.png"alt="数据流分析的DF+构造方法" /><figcaptionaria-hidden="true">数据流分析的DF<sup>+</sup>构造方法</figcaption></figure><p>同样以之前给出的数据流图为例，接下来对算法执行过程进行介绍。</p><ol type="1"><li>当从顶部开始遍历时，碰到的第一个J-edge为7→2，这使得DF<sup>+</sup>(7)，DF<sup>+</sup>(6)，DF<sup>+</sup>(3)，DF<sup>+</sup>(2)全部更新为{2}。更新完毕后检查<spanclass="math inline">\(DF^+(2) \subset DF^+(7)\)</span>，发现满足；</li><li>接下来可能被遍历到的J-edge有5条，假设从5→6开始，则更新<spanclass="math inline">\(DF^+(5)=DF^+(5)\cup DF^+(6)\cup\{6\}={2,6}\)</span>，且<span class="math inline">\(DF^+(6) \subsetDF^+(5)\)</span>成立；</li><li>接着是剩下的边，同样按这个方式进行遍历，其中遍历6→5时，会出现不一致条件，这样就需要在本次遍历完毕之后，再进行一次遍历。最后就可以得到所有点的DF<sup>+</sup>集合。</li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-23-13-52-37.png"alt="DJ-graph的例子" /><figcaption aria-hidden="true">DJ-graph的例子</figcaption></figure><p>当得到了单个节点x的DF<sup>+</sup>集合后，那么集合S的DF<sup>+</sup>(S)即为S中所有元素x的DF<sup>+</sup>(x)的并集。</p><h2 id="基于loop-nesting-forest的df集合构造方法">基于Loop NestingForest的DF<sup>+</sup>集合构造方法</h2><h3 id="在无环图下的df构造算法">在无环图下的DF<sup>+</sup>构造算法</h3><p>首先，在控制流图中存在循环结构，如果在CFG的深度优先生成树中有一条指向其祖先的边m→n，则m和n之间的子图构成了一个循环，且n被称为循环头。如果所有循环只有一个入口，那么这个控制流图被称为可规约的。下图中图(a)为可规约的，图(b)为不可规约的。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-23-22-46-49.png"alt="可规约循环和不可规约循环" /><figcaption aria-hidden="true">可规约循环和不可规约循环</figcaption></figure><p>对于可规约图，我们可以将所有的循环部分转换成一个节点，并将循环头和循环内部节点提取出来，构成循环森林（LoopNesting Forest）。下图展示了一个例子：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-23-22-52-11.png"alt="控制流图及其循环森林示例" /><figcaption aria-hidden="true">控制流图及其循环森林示例</figcaption></figure><p>使用循环森林的目的是：如果一个循环包含一个def，那么它的循环头也属于DF<sup>+</sup>。此外，当控制流图中两个不同的节点存在到同一个节点的路径，且这两个路径上没有其他的定义，那么这个节点属于DF<sup>+</sup>。在这两个规律基础上，我们提出一个应用于无循环的“无环图”的算法，并在结果上添加循环部分，得到最终DF<sup>+</sup>结果。</p><p>首先，对于无环图中的定义集合S，DF<sup>+</sup>(S)的计算过程如下：对控制流图使用拓扑顺序，利用前向数据流分析对满足两个不同节点到达同一个节点的情况进行分析，如果有多个节点可达节点x，则添加节点x到DF<sup>+</sup>(S)。例如上图中，节点6和节点8的即被多个定义到达，因此他们将会被加入至DF<sup>+</sup>(S)。该过程算法如下所示，其中UniqueReachingDef(v)记录了能到达节点v的唯一一个定义所在的基本块：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-23-23-56-32.png"alt="无环图中计算DF+的算法" /><figcaptionaria-hidden="true">无环图中计算DF<sup>+</sup>的算法</figcaption></figure><h3 id="将算法扩展至可规约图">将算法扩展至可规约图</h3><p>设HLC(v)为基本块v所在循环的循环头，那么对于集合S，存在公式如下。其中HLC(S)为S中所有节点所在循环头的集合，<spanclass="math inline">\(DF^+_{fwd}\)</span>为在无环图情况下求到的DF<sup>+</sup>集合。</p><p><span class="math display">\[DF^+(S)=HLC(S) \cup DF^+_{fwd}(S \cup HLC(S))\]</span></p><p>在之前的例子中，HLC({4,5,7,12})={2}，在无环图下得到的<spanclass="math inline">\(DF^+_{fwd}(\{2,4,5,7,12\})=\{6,8\}\)</span>，最终得到DF<sup>+</sup>(S)={2,6,8}。</p><h3 id="将算法扩展至不可规约图">将算法扩展至不可规约图</h3><p>不可规约图虽然在写代码的时候不容易出现，但是在优化的过程中经常出现。对于下图中的不可规约图，首先同样构建出他的循环森林。可以看到循环森林中循环头包括了两个节点，对应循环中的两个入口。在对不可规约图进行分析时，在无环图的基础上，添加一个辅助节点θ，我们连接所有循环头节点的前驱（u和s），并连接到循环头节点（v和w），最终得到图(d)。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-5-2022-04-24-09-44-43.png"alt="不可规约图的变换策略" /><figcaption aria-hidden="true">不可规约图的变换策略</figcaption></figure><p>在这样的基础上，可以通过上一节的算法先计算无环图下的DF<sup>+</sup>，接着利用循环森林，计算最终的DF<sup>+</sup>集合。</p><h2 id="总结">总结</h2><p>尽管所有这些算法都比原始算法更好，但由于这些算法无法在同一个编译器框架中使用，因此很难分出最优最劣。在实际中，虽然构造整个DF+集在经典构造算法中看起来时间复杂度很高，但它的代价实际上没有那么高，因为我们需要为很多变量进行插入Φ函数的计算，这些计算之间的结果是可以复用的。此外，我们还可以用Reconstruction的过程代替重新的构造，避免构造时的计算成本。还要注意的是，在SSA构造过程中，重命名变量过程通常需要花费更多的时间。</p><p>在LLVM中的SSA有更好的优化方式，该部分参考文章<ahref="https://blog.csdn.net/qq_29674357/article/details/78731713">《LLVMSSA 介绍》</a>。LLVM并不会一开始就将整个程序转化成SSA的形式，他将变量分为了两个部分：虚拟寄存器和内存。其中虚拟寄存器满足SSA，而内存则使用alloca/load/store的方法，使得对变量的读写变成了对某个地址的操作。这个技术被称为“alloca+mem2reg”技术，在优化的过程中采用alloca的非SSA形式，避免了繁琐的SSA构造和重构等过程。而在需要将部分内存访问转化为寄存器访问时，则利用mem2reg将程序的IR转化成SSA形式，这样子大大提高了编译的效率。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 4. SSA的基本析构算法</title>
    <link href="/2022/04/16/ssa-book-4/"/>
    <url>/2022/04/16/ssa-book-4/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--4.-ssa的基本析构算法">《SSA Book》- 4.SSA的基本析构算法</h1><p>本文对应原书3.2节，其介绍了如何对C-SSA进行最简单的析构，以及用简单的方法将T-SSA转化为C-SSA的方法。</p><p>SSA形式是为了在优化阶段能够更加高效和简单，当完成优化之后，就需要把他变成没有Φ函数的普通形式，这个过程称作SSA析构。</p><p>之前我们提到过，C-SSA的Φ网络中的变量具有互相不覆盖的live-ranges，这样子只需要做简单的指令替换，就可以完成SSA析构。析构的方法很简单，只需要在Φ函数的两个前驱基本块的末端增加两个复制语句。下图即为一个析构的例子：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-16-23-06-59.png"alt="面向C-SSA中Φ语句的析构方式" /><figcaption aria-hidden="true">面向C-SSA中Φ语句的析构方式</figcaption></figure><p>但是，针对上述过程存在一些问题：</p><ol type="1"><li>为什么有了live-ranges的互相重叠，就不能直接转换了呢？</li><li>如何将T-SSA转换为C-SSA呢？</li><li>基本快入口处的多个Φ函数是并行语句，转换后的复制语句是串行执行，如何进行转换呢？</li></ol><h2 id="朴素析构方法带来的问题">朴素析构方法带来的问题</h2><p>在对C-SSA的定义中提到了Φ函数对应的Φ-web。首先，如果x和y同时出现在同一个Φ函数中，x和y即为Φ-related的。所有被related到一起的变量构成了一个Φ-web。下面的算法利用并查集即可发现所有存在的Φ-web，union是并查集数据结构中的函数。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-17-21-04-24.png"alt="Φ-web发掘算法" /><figcaption aria-hidden="true">Φ-web发掘算法</figcaption></figure><p>接下来的这一部分困扰了我很久，我阅读原文理解的是：检测到Φ-web之后，如果存在Φ-web中活跃区间的冲突，则存在关键边上的问题，可能会导致lost-copyproblem和swapproblem，因此不能进行直接的Φ转换。但是，我实在没能理解为什么有活跃区间冲突后，就会导致这两个问题。</p><p>于是，我直接参考了论文《Practical Improvements to the Constructionand Destruction of Static Single AssignmentForm》。论文里面的逻辑关系感觉更容易理解。</p><h3 id="关键边critical-edges">关键边（Critical Edges）</h3><p>首先介绍关键边。关键边定义为具有多个后继块和具有多个前继块之间的边。图中的红色边即为关键边。当对Φ函数使用上面的方法进行分割后，如果程序沿着不通往φ函数的路径执行，那么不该发生的复制就会发生。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-19-22-00-53.png"alt="关键边以及析构Φ存在的问题" /><figcaption aria-hidden="true">关键边以及析构Φ存在的问题</figcaption></figure><p>为了解决这个现象，就需要将所有关键边分割开，然后再对Φ函数进行普通的替换。对于所有存在多个前驱的基本块B，判断每一个前驱是否具有其他的后继。如果Bi存在其他的后继，那么就在Bi和B之间添加一个基本快Bi'。遍历完毕后，再向新添加的基本块Bi'中增加赋值ai'=ai，并修改基本块B开头处的Φ语句中的ai为ai'。算法如下所示：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-17-22-57-26.png"alt="使T-SSA变成C-SSA的关键边分割算法" /><figcaptionaria-hidden="true">使T-SSA变成C-SSA的关键边分割算法</figcaption></figure><p>下图展示了变换的例子。添加基本块之后，之前提到的关键边带来的问题被消除了。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-17-23-23-16.png"alt="关键边分割实例" /><figcaption aria-hidden="true">关键边分割实例</figcaption></figure><p>上面最简单的关键边分割算法有很多问题：</p><ol type="1"><li>因为架构限制，异常处理代码等问题，编译器可能不允许分割给定的边；</li><li>添加大量复制操作可能会低效。虽然可以在后面的寄存器分配中进行合并（第22章中提到的合并启发式算法可以有效地移除这些副本），但是带着这么多复制进行编译也是不合适的。</li></ol><p>第21章会提出方法解决上面的问题。</p><h3 id="lost-copy-problem">Lost-Copy Problem</h3><p>关键边带来的复制语句的错误执行，在一定情况下会造成错误。典型的一个错误为：当进行Copyfolding优化之后，且存在一个或多个后向关键边时，将会发生“Lost-Copy”Problem。</p><p>下图即展示了“Lost-Copy”问题的例子。图(a)为原始的C-SSA。在进行复制传播之后，图(b)中变量y由x3进行了替代。图(c)显示了使用朴素算法将φ函数替换为复制语句的结果。显然，代码的结果发生了变化。而图(d)使用之前提到的关键边切割方法来解决问题。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-19-22-11-25.png"alt="导致Lost-Copy Problem的代码示例" /><figcaption aria-hidden="true">导致Lost-CopyProblem的代码示例</figcaption></figure><p>造成这一切原因的即为Copyfolding扩大了原先x3的活跃范围，这个活跃范围甚至覆盖了对x2的赋值。编译器在转换Φ函数的时候，必须要考虑插入的复制语句，对于非Φ函数的语句的后继基本块仍然有效。</p><h3 id="swap-problem">Swap Problem</h3><p>此外，同样是Copyfolding导致的另一个问题。下图给出了一个案例。图(a)为原始C-SSA，图(b)为进行了常量折叠之后的代码。图(c)显示了使用朴素算法将φ函数替换为复制语句的结果。因为Φ语句原来是并行执行的，而这样的直接转换破坏了并行特性，导致了a3与b3之间的互相干涉，使得结果错误。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-19-23-23-40.png"alt="导致Swap Problem的代码示例" /><figcaption aria-hidden="true">导致Swap Problem的代码示例</figcaption></figure><p>基本块开头的多个Φ函数在进行析构的过程中，将会为前驱添加多个复制语句。如果其中一个复制语句的结果，是另一个复制语句的操作数，那么复制语句的不同顺序则会对结果产生影响。下面的算法会自动保存上述复制语句的结果，以实现并行的效果。使用算法后可以得到上图中的图(d)，析构结果再次正确。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-4-2022-04-18-21-17-58.png"alt="用顺序复制操作的序列替换并行Φ函数" /><figcaptionaria-hidden="true">用顺序复制操作的序列替换并行Φ函数</figcaption></figure><h2 id="对朴素析构算法的总结">对朴素析构算法的总结</h2><p>综上所述，进行了优化算法之后得到的T-SSA，存在Φ-web的变量干涉的现象。一旦存在变量干涉，则可能会导致如Lost-CopyProblem和SwapProblem这样的错误。针对这些错误，本章目前只讲了解决这些问题的最朴素方法（切割关键边，并行转串行语句的方法），后续会有更实际高效的析构方法。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>编译后端优化：If-Conversion算法与LLVM实现</title>
    <link href="/2022/04/14/back-end-opt-1/"/>
    <url>/2022/04/14/back-end-opt-1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1id="编译后端优化if-conversion算法与llvm实现">编译后端优化：If-Conversion算法与LLVM实现</h1><p>在之前的某个项目中收到了这样的需求：给定一个无环控制流图，需要利用select等操作，消除其所有的分支，将其变成一个基本块。上网搜索现有轮子时，发现了大佬写的应用于GPU单指令多数据流的If-Conversion编译优化算法，能够很好地解决需求中的问题。于是我便照葫芦画瓢，直接在LLVM上实现了一个简单的Pass，并按照需求做了一些调整。</p><p>可能由于自身本领不够硬，看大佬的文章时理解得还是不太到位。因此我基于自己在实现Pass过程中的理解，简述一下这个算法，并对算法的某些部分在LLVM上的实现进行介绍，也算自己做一个笔记了。</p><p>附上大佬的文章地址：<ahref="https://zhuanlan.zhihu.com/p/157421035">针对GPU单指令多数据流的编译优化算法</a></p><h2 id="算法总览">算法总览</h2><p>使用Pass前后的数据流图如下图所示，稍微对具体内容做了一下屏蔽：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/back-end-opt-1-2022-04-16-13-41-36.png"alt="Pass前后的数据流图对比" /><figcaption aria-hidden="true">Pass前后的数据流图对比</figcaption></figure><p>该Pass地实现整体可分为3个步骤，其中前2个步骤属于If-Conversion算法部分：</p><ol type="1"><li>计算控制依赖（Control Dependence，CD）；</li><li>谓词分析：计算每一个基本块被执行的条件，并将被执行的条件与实际条件变量绑定；</li><li>代码生成：基于分析结果生成新的代码。</li></ol><h2 id="step-1.-计算控制依赖">Step 1. 计算控制依赖</h2><h3 id="控制依赖定义">控制依赖定义</h3><p>首先，算法需要计算基本块之间的控制依赖关系。对于两个基本块X和Y，Y是X的控制依赖的条件是：</p><ol type="1"><li>从X到Y存在一条有向路径P，P中除X以外的任意基本块Z都被Y后继支配；</li><li>X不被Y后继支配。</li></ol><p>其中，后继支配的定义和支配类似，如果从节点y到出口节点的每一条路径都经过节点x，则x为y的后继支配节点，记作xpdom y。同样的，对于x pdom y，不存在节点z，使得x pdom z 且 z pdom y。则x为y的直接后继支配节点，记作x ipdom y。</p><p>对控制依赖的概念进行理解：当控制依赖的条件满足时，那么通过X可以跳转到多个路径上。如果能够跳转到路径P，那么所有到出口的路径一定会经过基本块Y，即基本块Y一定会被执行；如果跳转到其他路径，则Y就不一定被执行了。</p><p>那么，对于一个节点Y，如果我们能找到该节点控制依赖所有的节点集合，并且记录下这些控制依赖中的集合跳转到“必定执行Y”的路径的条件，那么就可以得到决定基本块Y是否被执行的充要条件。</p><p>以下图为例，以其中的节点6为待分析的基本块节点。根据控制依赖的条件2，首先排除掉基本块2、4、5、7。节点1和3同时满足条件1和2，因此节点6的控制依赖集合为{1,3}。其中当控制依赖集合跳转到标记为绿色的两条路径时，基本块6必将被执行。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/back-end-opt-1-2022-04-15-23-05-00.png"alt="控制流图和其对应的控制依赖关系" /><figcaptionaria-hidden="true">控制流图和其对应的控制依赖关系</figcaption></figure><p>对基本块分支的不同选项进行编号，那么每个基本块对应的控制依赖可以用更具体的编号表示，例如基本块3的执行条件对应编号即为{-1}。</p><h3 id="计算控制依赖">计算控制依赖</h3><p>首先需要计算后置支配关系。在LLVM中，可以利用PostDominatorTree直接获得后置支配树PostDT，并通过PostDT-&gt;dominates(I,J)对基本块之间的后置支配关系进行判断。</p><p>其次，需要计算每个节点的直接后置支配节点。这个我在LLVM中没有找到对应的函数，因此直接使用了下面的算法。后继支配节点=直接后继支配节点+直接后继支配节点的后继支配节点，因此只需要删除所有“后继支配其他节点”的节点，剩下的即为直接后继支配节点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">for</span> CFG中的每一个节点n &#123;<br>    pdom(n) -= n;   <span class="hljs-comment">// 删除节点自己</span><br>&#125;<br><span class="hljs-keyword">for</span> CFG中的每一个节点n &#123;<br>    <span class="hljs-keyword">for</span> <span class="hljs-title function_">pdom</span><span class="hljs-params">(n)</span>中的每一个节点s &#123;<br>        <span class="hljs-keyword">for</span> <span class="hljs-title function_">pdom</span><span class="hljs-params">(n)</span>中的除去s的每一个节点t &#123;<br>            <span class="hljs-keyword">if</span> (t pdom s)   <span class="hljs-comment">// 删除“后继支配其他节点”的节点</span><br>                pdom(n) -= t;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>下面的表格展示了每个节点的后继支配和直接后继支配的结果。</p><table style="width:100%;"><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;">S</th><th style="text-align: center;">1</th><th style="text-align: center;">2</th><th style="text-align: center;">3</th><th style="text-align: center;">4</th><th style="text-align: center;">5</th><th style="text-align: center;">6</th><th style="text-align: center;">7</th><th style="text-align: center;">E</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">pdom</td><td style="text-align: center;">{E,7,1,S}</td><td style="text-align: center;">{E,7,1}</td><td style="text-align: center;">{E,7,6,2}</td><td style="text-align: center;">{E,7,3}</td><td style="text-align: center;">{E,7,6,4}</td><td style="text-align: center;">{E,7,6,5}</td><td style="text-align: center;">{E,7,6}</td><td style="text-align: center;">{E,7}</td><td style="text-align: center;">{E}</td></tr><tr class="even"><td style="text-align: center;">ipdom</td><td style="text-align: center;">1</td><td style="text-align: center;">7</td><td style="text-align: center;">6</td><td style="text-align: center;">7</td><td style="text-align: center;">6</td><td style="text-align: center;">6</td><td style="text-align: center;">7</td><td style="text-align: center;">7</td><td style="text-align: center;">{}</td></tr></tbody></table><p>得到每个节点的直接后继支配后，即可以计算控制依赖关系，可以直接通过控制依赖的两个条件得到，算法如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">for</span> CFG中的边[x,y,label] &#123;  <span class="hljs-comment">// label为true表示X为true时跳转的边</span><br>    <span class="hljs-keyword">if</span> (y pdom x)<br>        <span class="hljs-keyword">continue</span>;   <span class="hljs-comment">// X不能被Y后继支配</span><br>    t = y;<br>    <span class="hljs-keyword">while</span>(t != ipdom(x)) &#123;<br>        CD(t) += x;<br>        t = ipdom(t);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>以上图例子中的控制流图为例，当分析边[1,2,true]时，t将依次遍历2，6，7。除了节点7之外的其他节点均满足“从1到这个节点路径上的所有节点都被该节点后继支配”。因此节点1将会被添加至CD(2)和CD(6)之中。其他边的计算方法同理，最终得到所有节点的控制依赖如下表所示，没有编号的即为一定会被执行的基本块：</p><table><thead><tr class="header"><th style="text-align: center;">n</th><th style="text-align: center;">1</th><th style="text-align: center;">2</th><th style="text-align: center;">3</th><th style="text-align: center;">4</th><th style="text-align: center;">5</th><th style="text-align: center;">6</th><th style="text-align: center;">7</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">CD(n)</td><td style="text-align: center;">{}</td><td style="text-align: center;">{1}</td><td style="text-align: center;">{-1}</td><td style="text-align: center;">{2}</td><td style="text-align: center;">{-2,3}</td><td style="text-align: center;">{1,3}</td><td style="text-align: center;">{}</td></tr></tbody></table><h2 id="step-2.-谓词分析">Step 2. 谓词分析</h2><p>首先，上述分析结果存在一个问题。比如对于基本块4，他的控制依赖集合是{2}，但是2是否执行取决于它的控制依赖集合{1}，即需要将基本块4的执行条件更新为{1,2}。这一步更新只需要使用简单的数据流方法更新即可。为了区别于控制依赖，对于基本块n，更新后的执行条件我们用K(n)表示，最终得到的结果为：</p><table><thead><tr class="header"><th style="text-align: center;">n</th><th style="text-align: center;">1</th><th style="text-align: center;">2</th><th style="text-align: center;">3</th><th style="text-align: center;">4</th><th style="text-align: center;">5</th><th style="text-align: center;">6</th><th style="text-align: center;">7</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">K(n)</td><td style="text-align: center;">{}</td><td style="text-align: center;">{1}</td><td style="text-align: center;">{-1}</td><td style="text-align: center;">{1,2}</td><td style="text-align: center;">{-2,3}</td><td style="text-align: center;">{1,3}</td><td style="text-align: center;">{}</td></tr></tbody></table><p>其次，这些基本块的控制依赖集合通常有多个元素，需要将多个元素的条件整合到同一个变量中，并利用该变量作为是否执行该基本快操作的前提。借用GPU里面的概念，我们把这些整合后得到的条件变量称作谓词（Predicate）。</p><p>谓词的生成其实比较简单。首先我们对上一步中分析得到的控制依赖集合进行一个编号，下图给出一个可能的编号结果，其中基本块n的编号为P(n)：</p><table><thead><tr class="header"><th style="text-align: center;">n</th><th style="text-align: center;">1</th><th style="text-align: center;">2</th><th style="text-align: center;">3</th><th style="text-align: center;">4</th><th style="text-align: center;">5</th><th style="text-align: center;">6</th><th style="text-align: center;">7</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">K(n)</td><td style="text-align: center;">{}</td><td style="text-align: center;">{1}</td><td style="text-align: center;">{-1}</td><td style="text-align: center;">{1,2}</td><td style="text-align: center;">{-2,3}</td><td style="text-align: center;">{1,3}</td><td style="text-align: center;">{}</td></tr><tr class="even"><td style="text-align: center;">P(n)</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">-1</td><td style="text-align: center;">2</td><td style="text-align: center;">3</td><td style="text-align: center;">4</td><td style="text-align: center;">0</td></tr></tbody></table><p>这样，我们可以创建4个谓词P1-P4。当基本块1和2尾端的跳转条件均为true时，谓词P2为true。基于谓词将控制流图改写成下列形式。其中“Px:By”的形式表示当谓词Px为true时，执行基本块By中的语句。Cy表示基本块By结尾处跳转时的条件变量。这样就完成了从带分支的控制流图到单个基本块的转变。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C">B1;<br>P1 = C1;<br>P1 : B2;<br>P2 = C1 &amp; C2;<br>!P1 : B3;<br>P3 = C1 &amp; C3;<br>P4 = !C2 &amp; C3;<br>P2 : B4;<br>P3 : B5;<br>P4 : B6;<br>B7;<br></code></pre></td></tr></table></figure><h2 id="step-3.-代码生成">Step 3. 代码生成</h2><p>这一步需要对LLVMIR进行更改，使指令全部被复制至一个基本块中。这里需要考虑两个问题：</p><ol type="1"><li>目标是否支持谓词的执行方式，如果不支持则要做一些面向目标的修改；</li><li>LLVM IR为SSA形式，要注意生成新的基本块时不要打破SSA约束。</li></ol><p>在这里，第一个问题涉及一些项目细节，就不展开介绍了。针对第二个问题，在我们使用IRBuilder或者其他方法创建新的Instruction时，需要使用RemapInstruction函数，将新的Inst和旧控制流图中的Inst绑定起来，这样子就可以保证最后生成的基本块满足SSA特性。绑定后即可通过ReplaceInstWithInst或者其他方法添加、替换、删除指令了。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LLVM</tag>
      
      <tag>编译原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 3. SSA的基本构造算法</title>
    <link href="/2022/04/10/ssa-book-3/"/>
    <url>/2022/04/10/ssa-book-3/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--3.-ssa的基本构造算法">《SSA Book》- 3.SSA的基本构造算法</h1><p>上班了，更新速度明显减慢 /(ㄒoㄒ)/~~，争取每周能有2次更新。</p><p>原书中第三章包含了构造、析构、转换等多个算法，内容较长。因此将本章内容分为两节，本节先介绍利用支配树构造最小SSA的方法。</p><h2 id="最小ssa构造流程总览">最小SSA构造流程总览</h2><p>构造SSA的过程可以分为两步：放置Φ函数，变量重命名。针对Φ函数放置过程，本书采用构造支配树的方式，选取放置Φ函数的位置。其整体流程如下：</p><ol type="1"><li>构造支配树</li><li>计算变量的支配边界</li><li>在变量的支配边界添加Φ函数</li></ol><h2id="支配树dominator-tree与支配边界dominance-frontier">支配树（DominatorTree）与支配边界（Dominance Frontier）</h2><p>首先我们考虑最粗暴的方式，即在所有具有多个前驱的基本块开头添加Φ函数，对变量进行聚合。这样子虽然的确满足SSA的定义，但是会插入很多不必要的Φ函数。</p><p>假设一个程序的控制流图如下图所示，对于变量x，存在两个定义分别在基本块A和E中。其中，基本块D就具有多个前驱，按照最粗暴的算法，需要在这里放置一个Φ函数用来聚合前驱中变量x的值。很显然，此处的Φ函数是不必要的，因为基本块D处的x变量值是确定的。相对的，在基本块F添加Φ函数就是必要的了，因为变量x的值在此处是不确定的。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-10-15-45-31.png"alt="Fig 1. 在不同基本块添加Φ函数的必要性" /><figcaption aria-hidden="true">Fig 1.在不同基本块添加Φ函数的必要性</figcaption></figure><p>那么，在什么样的基本块添加Φ函数是必要的呢？这就需要支配树和支配边缘的概念了。关于支配的概念在龙书中提及：</p><blockquote><ul><li>支配（dominate）：如果所有从流图的入口结点entry到结点n的路径都经过结点d，则称d支配n，记为ddom n；</li><li>严格支配（strictly dominate）：如果d dom n且d !=n，那么d严格支配n，记为d sdom n；</li><li>直接支配（immediate dominate）：如果d domn且n的其他支配者都支配d，那么d直接支配n，记作d idom n。</li></ul></blockquote><p>直观的理解，当控制流图中存在d domn时，只要程序执行到基本块n，那么说明基本块d一定被执行过（反之不成立）。其中，直接支配和后续研究关系最大。在上图中存在的直接支配关系为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs C++">entry idom A; <br>A idom B;<br>A idom C;<br>A idom D;<br>A idom F;<br>C idom E;<br></code></pre></td></tr></table></figure><p>将所有的直接支配关系绘制成树的形式，即得到了支配树（DominatorTree）。上面例子的支配树如下图所示：</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-10-16-31-58.png"alt="Fig 2. 对应支配树" /><figcaption aria-hidden="true">Fig 2. 对应支配树</figcaption></figure><p>在支配树中，我们仍然无法得到能决定“在F放置Φ函数是必要的，在D放置Φ函数是冗余”的原因，我们需要进一步计算支配边界（DominanceFrontier，DF）。支配边界的定义如下所示：</p><blockquote><p>基本块x的支配边界DF(x)是满足下列条件的所有w的集合：x支配w的一个前驱，但是不严格支配w。</p></blockquote><p>以图1中的程序为例求解DF(C)，首先排除所有C严格支配的基本块（E）。剩下的基本块中，C支配D的前驱（C）和F的前驱（E），因此DF(C)={D,F}。类似的，对于与变量x相关的两个基本块A和E，他们的支配边界为DF(A)={Ø}，DF(E)={F}。</p><p>支配边界是支配节点和非支配节点的分界线。每一个基本块都有其支配的节点的集合。如果一个定义了变量的基本块的所有支配的基本块中，没有别的对这个变量的定义，那么这些被支配基本块中该变量的值是确定的。一旦到了支配边界，这个变量具体的值就要考虑这个支配边界的其他的前驱基本块了。因此，变量的支配边界均为Φ函数的候选点。</p><p>在之前的例子中，存在x定义的基本块集合{A,E}的支配边界集合为{F}，因此要在基本块F的开始处添加φ函数。当添加了Φ函数后，基本块F中也存在x的定义了，因此需要对{A,E,F}重复进行支配边界分析。由于DF(F)={}，因此φ函数添加完毕。</p><h2 id="添加φ节点的具体算法实现">添加Φ节点的具体算法实现</h2><p>针对上一节给出的例子，本节将会给出构造SSA过程各部分的算法实现。</p><h3 id="支配树与支配边界构造算法">支配树与支配边界构造算法</h3><p>在SSAbook中没有对构造支配树的方法进行介绍，经典支配树构造的算法包括SLT和semi-NCA算法，可以参考文章：https://zhuanlan.zhihu.com/p/365912693。</p><p>当得到基本块之间的支配关系后，即可通过下面的算法构造每一个基本块的支配边界。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-12-21-30-26.png"alt="Alg 1. 计算控制流图的支配边界" /><figcaption aria-hidden="true">Alg 1.计算控制流图的支配边界</figcaption></figure><p>以下图(a)中的数据流图为例，我们使用上面的算法进行分析。所有边中，非严格支配的边的集合只有D→E和F→G。图(b)中对控制流图进行重整，并标注出非严格支配边，这张图被称作DJ-graph（Dominanceedges &amp; Join edges），非严格支配的边被称作Joinedge（J-edge）。接着，对于这些J-edge使用算法。节点E被先后添加至DF(D)与DF(C)中，而节点G被添加至DF(F)、DF(E)与DF(B)中。图(c)中的边即为节点和该节点的支配边界间的连线。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-12-21-53-46.png"alt="Fig 3. 示例控制流图和其对应的DJ-grpah，DF-graph以及DF+-graph" /><figcaption aria-hidden="true">Fig 3.示例控制流图和其对应的DJ-grpah，DF-graph以及DF<sup>+</sup>-graph</figcaption></figure><p>此外，图(d)中展示了DF-graph图上的扩展。针对DF-graph中的连续边如C→E和E→G，将会添加边C→G到DF<sup>+</sup>-graph图中。之前提到过Φ节点的添加是迭代式的，添加的Φ函数本身也是一个def。假设在基本块C存在对变量x的定义，当向E添加了Φ函数之后，由于E有了关于变量x的定义，因此需要向基本块G继续添加Φ函数。提前计算好DF<sup>+</sup>-graph能避免计算支配边界过程中的冗余计算。这部分算法将会在第四章中“更复杂巧妙的构造算法”进行介绍。</p><h3 id="φ函数添加算法">Φ函数添加算法</h3><p>基于前文的分析，添加Φ函数的方法显而易见了。下图展示了插入Φ节点的标准算法。对于一个变量，算法将所有的定义所在基本块添加至集合W中。然后从W中取出基本块X，向X的支配边界添加Φ函数，并把添加了Φ函数的基本块添加至集合W中。如此循环直到W集合为空。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-12-22-06-40.png"alt="Alg 2. 向控制流图中添加Φ函数" /><figcaption aria-hidden="true">Alg 2. 向控制流图中添加Φ函数</figcaption></figure><h2 id="变量重命名">变量重命名</h2><p>添加了Φ函数之后，需要对变量进行重命名。变量重命名算法如下图所示。对于任意一个变量v，算法使用v.reachingDef来记录当前替换变量的值。算法前序遍历支配树中的基本块，并依次遍历基本块中的每一条指令。进行操作：</p><ol type="1"><li>如果该语句非Φ函数，且使用了变量v，那么则更新v.reachingDef的值，并用更新后v.reachingDef的值替代此处变量v；</li><li>如果被该语句定义了变量v，那么同样先更新v.reachingDef的值，并创建一个新变量v'替代此处的定义，并对v和v'的reachingDef属性进行更改；</li><li>当遍历完所有语句，则对于所有这个基本块的后继基本块的Φ函数，如果Φ函数使用了变量v，则采用类似操作1中的方法，对Φ函数中的变量进行替代。</li></ol><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-13-20-39-50.png"alt="Alg 3. 变量重命名算法" /><figcaption aria-hidden="true">Alg 3. 变量重命名算法</figcaption></figure><p>上述算法中，最重要的就是“更新v.reachingDef的值”的方法，该方法被包含在函数updateReachingDef(v,i)中，算法如下所示。这个算法搜索v的所有定义，直到找到支配i的最接近的定义（注意是支配，而不是严格支配），然后使用此定义更新v.reachingDef。这样子语句i被v.reachingDef的定义所支配，因此i中的变量v理所当然的可以被v.reachingDef所替换。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-13-20-41-26.png"alt="Alg 4. updateReachingDef(v,i)函数实现" /><figcaption aria-hidden="true">Alg 4.updateReachingDef(v,i)函数实现</figcaption></figure><p>下图以一个例子展示了对程序中x变量重命名的全过程，按步骤进行简单介绍：</p><ol type="1"><li>在入口处对x.reachingDef进行初始化；</li><li>语句l1满足情况2，首先更新reachingDef的值为当前语句，然后将def的结果替换为x1；</li><li>遍历完基本块A的两个语句，需要看两个后继中的Φ语句。刚好都没有Φ语句，那没事了，继续遍历；</li><li>类似的，基本块B的l2语句情况类似，同样更新reachingDef的值为当前语句，替换为x2；</li><li>遍历完B，需要查看后继中的Φ语句。对于l5中的use，需要根据情况3进行更新。这个时候最近的支配def即为B中的x2，因此将其替换为x2；</li><li>接着回到基本块C，C中出现的l3语句满足情况1，支配l3的定义为基本块A中的l1，因此将其替换为x1；</li><li>情况1-3展示完毕，后续同理……</li></ol><p>对于reachingDef属性的具体存储，因为其包含了一些搜索和回退过程，在实现的过程中通常会分配额外的内存对过程值进行记录。记录的方法包括使用栈和槽（slot-based）的，前者更节省空间，后者更加高效。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-3-2022-04-13-21-15-20.png"alt="Fig 4. 变量重命名的过程实例" /><figcaption aria-hidden="true">Fig 4. 变量重命名的过程实例</figcaption></figure><h2 id="关于基本ssa构造方法的总结">关于基本SSA构造方法的总结</h2><p>使用本章最简单的构造方法得到的SSA具有下列特点：</p><ol type="1"><li>它是minimal SSA；</li><li>它是non-pruned SSA，有些插入的Φ函数可能是dead的，需要删除；</li><li>它是C-SSA，可以被直接送到SSA析构算法中进行转化；</li><li>它是strictSSA，即每个use都一个def所支配。这是因为它在构造过程中采用了支配边界的概念进行Φ函数插入，而不是简单的通过joinset进行判断（注：基本块集合S的joinset即为在CFG中可以被S的两个或更多不同元素通过不相交路径到达的节点）。</li></ol>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 2. SSA种类和特性</title>
    <link href="/2022/04/09/ssa-book-2/"/>
    <url>/2022/04/09/ssa-book-2/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--2.-ssa种类和特性">《SSA Book》- 2. SSA种类和特性</h1><p>本章首先介绍了SSA和non-SSA下的def-use链特性进行了分析。同时本章介绍了几种不同形式的SSA，包括最小SSA（MinimalSSA）、严格SSA（Strict SSA）、剪枝SSA（PrunedSSA）和常规和转换SSA（Conventional and transformed SSA）</p><h2 id="def-use与use-def链">Def-use与use-def链</h2><p>Def-use与use-def链并不是SSA特有的东西，非SSA形式下的每一个变量的所有def和use之间仍然存在def-use与use-def链。但是在非SSA形式中，由于存在多个def和use，需要用类似二维数组的形式，对变量所有的def和use之间的关系进行记录。然而，在SSA形式中每个变量只被def一次。因此每个变量仅需记录所有它的use，每一个use都对应了一条def-usechain，这样就可以用更为稀疏的形式对def-use关系进行存储。</p><p>SSA形式下的def-use与use-def链的优势可以总结为：</p><ol type="1"><li>数量相较non-SSA下普遍更少，并且更加便于数据存储；</li><li>更加方便数据流分析。SSA形式下的数据流分析只需要在def处保存数据流分析信息。在更新某一个def的数据流信息时，可以直接利用该条def所使用的变量对应的use-def链，获得存储在其他def处的数据流信息。</li></ol><h2 id="不同形式的ssa">不同形式的SSA</h2><p>在满足SSA定义“每个变量在程序中有且只有一个赋值语句”的前提下，Φ函数可以被插入到程序中不同的位置，因此同一个程序对应的SSA形式不是唯一的。通过增加更多约束，可以细分为不同SSA类型。</p><h3 id="最小ssaminimal-ssa">最小SSA（Minimal SSA）</h3><p>最小SSA指代的是“Φ函数数量最小的SSA形式”。构建SSA的过程包含两个阶段：放置Φ函数、变量重命名。在放置的过程中，为同一个原始变量两个不同定义到出口的所有路径交汇处添加Φ函数，既能构成具有Minimality特性的最小SSA形式。在下一章中展示的构造SSA方式即为构造最小SSA的方法。</p><blockquote><p>TODO：为什么这样生成就能得到Minimal SSA呢？</p></blockquote><h3 id="严格ssastrict-ssa">严格SSA（Strict SSA）</h3><p>如果每个变量在从入口到出口的每条路径上，use之前都已被def，那么SSA是严格的。利用支配（dominate）的概念对其进行描述，若SSA中每个use被其def支配，那么称为严格SSA。下图展示了non-strict和strictSSA。相较图(a)中的SSA形式，图(b)中新添加了两个Φ函数。很明显，图(b)中的SSA并不是MinimalSSA。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-2-2022-04-09-18-34-30.jpg"alt="non-strict SSA及其对应的strict SSA。⊥表示未定义的值" /><figcaption aria-hidden="true">non-strict SSA及其对应的strictSSA。⊥表示未定义的值</figcaption></figure><p>严格SSA带来的好处主要在特定算法中体现，包括：</p><ol type="1"><li>更好判断在一个点上，变量是否是活跃的（Live），可以应用于到达定值分析等；</li><li>测试两个变量是否相互干涉（interfere），可以用作图染色中，不需要另外显式构造变量间干涉图。</li></ol><h3 id="剪枝ssapruned-ssa">剪枝SSA（Pruned SSA）</h3><p>剪枝SSA是在最小SSA的基础上，添加约束“如果变量在基本块的入口处不是活跃的，就不必插入Φ函数”。以下图为例，图(a)是没有经过修剪的最小SSA形式，在经过了值编号（Valuenumbering）之后，Z1与Z2被认为是死变量，Z3与Y3具有相同的值。因此，关于Z3的Φ函数被删除，得到了图(b)中的剪枝SSA。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-2-2022-04-09-22-07-40.png"alt="剪枝前后的SSA" /><figcaption aria-hidden="true">剪枝前后的SSA</figcaption></figure><p>可以发现，剪枝SSA的Φ函数数量可以小于最小SSA中的数量。这是因为最小SSA的minimality是指的是“不在生成的SSA上进行优化”前提下的Φ函数数量最小，而剪枝则对SSA本身进行了优化。</p><p>针对剪枝具体进行的阶段，书中给出了两种策略：</p><ol type="1"><li>先建立好最小SSA，然后进行死代码消除</li><li>在构造SSA的时候，对Φ函数进行活跃分析，删除不活跃的Φ函数</li></ol><p>第三章提出了半剪枝SSA（Semi-prunedSSA）。因为剪枝SSA需要进行活跃变量分析，有较高的代价，所以可以考虑先把最小SSA变成半剪枝SSA的形式。半剪枝SSA对只存在于单个基本块中的局部变量生成的Φ函数进行消除。这样，在进行活跃变量分析时，部分变量被消除，活跃分析代价变少。</p><blockquote><p>注：LLVM中使用Mem2reg构建SSA时，即为通过半剪枝SSA构造剪枝SSA的方法。</p></blockquote><h3 id="conventional-ssa和transformed-ssa">Conventional SSA和TransformedSSA</h3><p>如果两个变量的活动范围（Live-range）相交，它们就会相互干涉（interference）。从Φ函数出发，到所有Φ函数参数的定义连接起来，可以构成一个网络。当网络中的变量活跃范围互相不干涉时，则被称作传统（ConventionalSSA，C-SSA）。对C-SSA进行优化之后，可能会破坏这个性质，即被称作变形SSA（TransformedSSA，T-SSA）。</p><p>下图展示了同一个控制流图的不同状态。图(a)为原始控制流图，图(b)为添加Φ函数并且重命名之后的SSA。这个SSA是最小SSA，同时也是C-SSA。在C-SSA的基础上进行复制传播（copypropagation），即可得到图(c)。可以发现，Φ函数中两个变量的网络在第一个基本块上重合，因此为T-SSA。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-2-2022-04-09-23-23-25.png"alt="复制传播将C-SSA转化成T-SSA" /><figcaption aria-hidden="true">复制传播将C-SSA转化成T-SSA</figcaption></figure><p>C-SSA形式在对SSA进行析构时（即将其转化为实际机器代码的过程）具有优势：C-SSA的析构过程是很简单的，直接将所有的定义和使用都被重命名以使用新变量，并且删除所有涉及这个等价类的Φ函数。以上图(b)为例，变量a2和a3被重命名为新的单独的变量，对应的Φ函数a4直接被删除。因此，在析构SSA过程中，首先要将T-SSA转化成C-SSA的形式。通常这个转化过程通过添加复制操作来完成。</p><p>其次，C-SSA形式更易于部分算法获得一些SSA的特性，这些特性在T-SSA中可能是难以被发现的。例如局部冗余消除（PRE）就利用了这些特性（第11章）。</p><p>除了以上两种情况，通常情况下都不会主动去维护SSA的Conventional性质。</p><h2id="关于干涉interference的进一步讨论">关于干涉（interference）的进一步讨论</h2><p>干涉概念的最终目的，是为了标明两个变量是否能通过同一个寄存器暂存。在之前的定义中，两个变量的live-range重叠，则认为两个变量是互相干涉的。这个对于干涉的定义实际上有些严苛了。实际上，可能存在“两个变量互相不干涉，但是他们live-range重叠”的情况。下面给出两个例子：</p><ol type="1"><li>如果两个变量在任何时间点都具有相同的值，那么他们之间是不干涉的；</li><li>可能两个变量的live-range在静态分析时是重叠的，但是可能会因为特殊的基本块跳转条件，导致实际执行时两个变量不会在同一时刻活跃，那么他们之间也是不干涉的。</li></ol><p>以上两个特例大多是可以通过静态分析过程发现的，这种优化后的干涉定义相较于简单且严苛的干涉定义，能使得部分算法取得更好的结果。</p>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《SSA Book》- 1. 介绍</title>
    <link href="/2022/04/07/ssa-book-1/"/>
    <url>/2022/04/07/ssa-book-1/</url>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="ssa-book--1.-介绍">《SSA Book》- 1. 介绍</h1><p>在知乎的编译优化相关书籍推荐中，看到了很多关于这本书的推荐，但是国内论坛关于这本书的讨论相对较少。《SSABook》从静态单赋值SSA的定义出发，讨论了构造、变换后重构、以及在SSA形式下不同编译算法的执行方式。此外，本书还介绍了很多高级SSA表示和用法，如果将来有时间，争取能对这部分进行补充。</p><h2 id="ssa的定义以及φ函数特性">SSA的定义以及Φ函数特性</h2><p>关于SSA的定义的文章遍地都是，就不在这里赘述了，只给出SSA的两个简单特性：</p><ol type="1"><li>每个变量在程序中有且只有一个赋值语句；</li><li>Φ函数将会被添加至控制流图中的控制流交汇点，用于聚合来自不同分支中的变量值。</li></ol><p>Φ函数的功能是很容易理解的，但是在计算机执行过程中，Φ函数究竟对应什么指令呢？书中针对这个问题进行了解答。Φ函数只存在于静态编译分析过程中，这些语句并不对应着目标硬件上某条指令。在SSA解构阶段，这些Φ函数将会被删除，并使用传统的复制操作对其进行序列化。此外，在部分SSAform中，同样存在部分扩展使得Φ函数存在对应的可执行指令，关于此部分将会在高级部分中进行讨论。</p><h2 id="ssa的优势">SSA的优势</h2><p>SSA最大优势来源于简化了数据流分析过程。传统数据流分析需要在每一个程序点处捕捉变量的信息，并利用格和流函数等概念，对这些程序点的信息值进行多次计算，得到不动点等信息。这使得在程序中每个程序点，都需要记录此处在数据流分析过程中信息的值，并在每一次运算过程中计算所有的值，即使在这些程序点中大部分信息没有改变。</p><p>然而，SSA形式下的数据流分析可以基于每个变量的def-use链进行分析。分析过程只需要记录每个变量定义处的信息，并通过def-use链更新信息。这大大减少了数据流分析的复杂度。这也使得程序员能够更加容易地编写数据流分析算法，调试难度更低。</p><p>下图中展示了传统形式和SSA形式下对于程序中x与y两个变量的零值传播分析对比。图(a)中在每个基本块的入口和出口处均设置了信息槽，用于记录当前位置x和y变量的值是否为0。可以看出，在大多数与两个变量无关的基本块处，入口和出口的信息是没有变化的，这造成了一定的浪费。</p><p>图(b)中展示了基于SSA形式下的数据流分析过程，可以发现，只需要在每个基本块的结尾设置与该基本块中定义的变量相关的信息槽，即可完成对整个控制流图的数据分析。在SSA形式下，需要的信息槽数量明显减少，数据流分析的效率可以得到提升。</p><figure><imgsrc="https://gqrelic-blog-data.oss-cn-shanghai.aliyuncs.com/ssa-book-1-2022-04-08-09-55-37.jpg"alt="使用SSA分析的控制流图示例" /><figcaption aria-hidden="true">使用SSA分析的控制流图示例</figcaption></figure><h2 id="关于ssa存在的谬论">关于SSA存在的谬论</h2><p>一部分人认为SSA可能存在一部分缺点，然而实际上针对这些缺点已经有了很好的解决方法。本书将会在后续部分中对这些可能存在的进行研究和解释。此处先给出部分SSA可能存在的缺点，以及对这些缺点进行讨论的章节：</p><table><thead><tr class="header"><th>SSA可能存在的缺点</th><th>解决策略</th></tr></thead><tbody><tr class="odd"><td>SSA增加了变量的数量</td><td>第2章展示了减少变量数量的优化方法</td></tr><tr class="even"><td>SSA难以维护</td><td>第3和5章展示了编译优化过程中对SSA结构的高效维护策略</td></tr><tr class="odd"><td>SSA析构时将带来大量复制操作</td><td>第3和21章展示了高效的SSA析构策略</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>编译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>编译原理</tag>
      
      <tag>SSA</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
